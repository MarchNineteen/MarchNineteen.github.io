{"meta":{"title":"Marcher","subtitle":null,"description":null,"author":"Marcher","url":"https://marchnineteen.github.io","root":"/"},"pages":[{"title":"关于我","date":"2016-12-05T00:00:00.000Z","updated":"2021-07-01T08:01:52.101Z","comments":false,"path":"about/index.html","permalink":"https://marchnineteen.github.io/about/index.html","excerpt":"","text":"一名默默无闻的码农，Java程序员，喜欢研究新的技术。目前正在补java基础。"},{"title":"文章分类","date":"2017-12-05T16:02:01.000Z","updated":"2021-07-01T08:01:52.101Z","comments":false,"path":"categories/index.html","permalink":"https://marchnineteen.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-25T00:00:00.000Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"tags/index.html","permalink":"https://marchnineteen.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2021-07-01T08:01:52.101Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"md/rpc/simpleRpc.html","permalink":"https://marchnineteen.github.io/md/rpc/simpleRpc.html","excerpt":"","text":"简单设计一个rpc框架v1 基础设计 客户端&amp;服务端 网络请求 序列化相关概念什么是rpc rpc，远程过程调用，简单来说就是远程方法调用，用代码的方式来说就是直接调用service方法，客户端调用就像调用本地接口一样。 简单的工作流程： 客户端发起请求，请求会带上相关参数，比如主机信息，参数信息，版本信息，调用标识，调用协议等等。服务端接收信息，执行过程，将结果返回。 涉及到相关因素： 消息封装格式。可以使用应用层的http协议，也可以使用传输层的tcp协议。 数据格式。客户端请求所需要携带的参数以及相关格式。 序列化。信息在网络传输中要以二进制格式进行传输。序列化和反序列化，是对象到而二进制数据的转换。常见的序列化方法有JSON、Hessian、Protostuff等。 网络IO模型。可以采用非阻塞式同步IO,也可以在服务器上实现对多路IO模型的支持。 线程模型。在高并发请求下，可以使用单个线程运行服务的具体实现，但是会出现请求阻塞等待现象。也可以为每一个RPC具体服务的实现开启一个独立的线程运行，最大线程数有限制，可以使用线程池来管理多个线程的分配和调度。 v2 增加zk 作为注册中心 增加服务端心跳检测v3 异步请求&amp;线程池 提高资源利用 注册中心持久化 方式宕机无法访问v4 客户端新增注册中心监听器 实时更新注册中心"},{"title":"","date":"2021-07-01T08:01:52.101Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"md/随笔/20191221.html","permalink":"https://marchnineteen.github.io/md/%E9%9A%8F%E7%AC%94/20191221.html","excerpt":"","text":"2019/12/21 小雨 周六 公司加班ing 写在前面这段时间心里一直很沉闷，心里也纠结了很久，生活、工作两方面，还是理一理，总结一下吧。理完之后，从新启程。 生活从大姨给我介绍过一个之后，接二连三的由朋友介绍或者聚会上遇到新的女生。 其中一个女生怎么说呢，没有吸引我的点吧，所以也没有喜欢，后来就成为朋友，但是感觉她还是对我有想法，先保持距离吧。 另一个呢，参加朋友聚会的时候遇到，但是比较现实吧，需要房子什么的，一起吃过两次饭，平常也还聊得来，但是太被动了，不过可能是对我没什么意思吧，自己可能就很容易喜欢上一个人吧，是病，得治。搞的自己一天到晚胡思乱想，影响心情。其实呢知道还是不太适合的，所以还是少联系，保持距离吧，不要想着去约她啊什么的，做好自己的事情，久而久之，自然就忘记了。嗯！就这样吧，交给时间，之前也是这样过来的，何况现在的自己更加强大了。嘻嘻！ 还有就是，今天丁伟和红红领证啦，先祝福一波。不过也已经不会有什么羡慕了，感觉遇到一个各方面都合适的人真的挺难的，这种事情随缘吧。这几天比较沉闷的原因还是因为上面那个女生，自己控制不了自己的想法，心里素质不行，还需要锻炼，感情上呢，别太轻易用心吧。先阶段还是以工作为中心吧，努力提升自己，让自己变得更加优秀，各方面的。再在遇到自己喜欢的女生的时候可以不用自卑，可以考虑其它原因，单单只是因为喜欢，嗯，就是这样，坚持自己的初心。女生要嫁给爱情，那么男生就娶一个嫁给爱情的女生。 工作哎！工作上不知道咋说，很烦。 第一，天天加班，每周六加班，而且加的是没什么意义的班，真的很讨厌。所以偷偷懒，做做自己的事情吧。老项目要沉下心来把东西改好，明年要走了，代码质量也要保证，再坚持几个月吧，确实已经受够了，自己的职业规划也不允许在这里了，所以明年不管待遇怎么样，出去试试吧，待在这里，影响发展。 第二，给任务要搞vue，uni-app，虽然说语言可能不是从头开始，但是画页面什么的，从0开始，也还是需要花时间的，现在呢要准备明年的面试，这个在公司有空的时候再搞吧，而且公司也没给额外的时间学习，我自己的时间我有自己的安排。所以也别太放心上了，不是重点。嗯！ 总结马上年底了，各种事情都会聚到一起，自己多点耐心吧，好好安排好，事情一件一级去解决。重点就是改好好沉下心来学习啦，明年还得面试呢，加油，加油！努力可能不会有回报，但是不努力连这个可能都没有了。脚踏实地吧。加油！"},{"title":"","date":"2021-07-01T08:01:52.101Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"md/面试/dahua.html","permalink":"https://marchnineteen.github.io/md/%E9%9D%A2%E8%AF%95/dahua.html","excerpt":"","text":"1.linux常用命令例如:查看XXX端口是否被占用,cpu占用率等等netstat -anp|grep 8080 netstat -nultp ps –ef|grep java kill top jobs tar –zxvf chmod 文件权限 chown文件拥有者和群组 2.Nginx技术SSl配置,跨域访问负载均衡(几种策略)跨域访问: allow-origin:allow-methods:当跨域请求需要携带cookie是，请求头中需要设置Access-Control-Allow-Credentials:true。Access-Control-Allow-Credentials值为true时，Access-Control-Allow-Origin必须有明确的值，不能是通配符(*) 负载均衡: https://segmentfault.com/a/1190000022440540 使用upstream模块定义后端服务器策略：轮询 默认方式weight 权重，ip_hashleast_conn 3 接口访问慢问题排查。4 线程池的使用,几大参数,参数解析5 Springcloud使用过哪些组件,在项目中起什么作用。6 Springboot相互依赖问题的解决原理,几种注入注解的区别@Autowired@Resource.spring生命周期，在bean初始化的时候，填充属性的时候，去加载需要依赖的对象，这个时候发现存在循环依赖。在A对象初始化的时候，先在二级缓存中提前暴露自己，以便在B对象需要A的时候能获得引用。 spring生命周期提供了很多修改bean的接入点(beanPostProcessor)，三级缓存是为了解决bean的引用被替换的问题，提前获取对象的引用，提前把对象给替换了AOP。 @Autowire 由spring提供，默认根据type注入，当同一个类型有多个实现类时，会造成无法选择具体的注入，一般配合@Qualifier使用，根据名称注入。@Resource 由java提供，默认按照byName注入，也提供byType注入。@Resource装配顺序 如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常 如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常 如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配； 7 Redis几种存储类型,redis分布式锁实现原理.redis的持久化策略存储类型:String, List, Set,Hash, Zset, redis分布式锁实现原理:利用redis string操作的setnx, 8 垃圾回收器:新生代几种,老年代几种,常用的组合。项目上用的是哪种?有什么优点G1 region防止全堆扫描 每个region单独回收 整体是标记整理算法 局部是标记复制算法 新生代Serial(单线程) ParNew(Serial多线程版本) Parallel Scavenge(多线程，吞吐量优先)老年代Serial Old CMS（标记清除算法，容易导致内存碎片,造成full GC） Parallel Old 收集器 常用的组合 ParNew + CMSParallel Scavenge + Parallel Old 9 synchronized锁升级原理,Look锁,独占与共享synchronized jvm层面 10 对AQS的理解核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 11 Dubbo的实现原理12 几种Mq的优缺点,项目上为什么用XXXMq13 mysql索引有几种,底层数据结构是什么,为什么会用到这种数据结构,优点是什么?14 针对项目上使用的技术随机发问"},{"title":"","date":"2021-07-01T08:01:52.101Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"md/面试/question.html","permalink":"https://marchnineteen.github.io/md/%E9%9D%A2%E8%AF%95/question.html","excerpt":"","text":"1、讲讲hashMap的底层原理？ 2、redis中的缓存击穿是怎么处理的？ 3、InnoDB中的索引结构是什么样的？ 4、讲讲聚集索引和非集聚索引的区别？ 5、数据库sql优化处理是怎么处理的？ 6、算法：找出一个字符串中第一次出现并只出现一次的字符下标？ 7、算法：计算0-100内的素数之和 8、讲讲redis缓存击穿和缓存穿透分别有什么区别？ 9、讲下springmvc中，用户从客户端发起一个请求是如何进入到你的controller里的？ 10、讲一下spring中bean的注入过程？ 11、讲一下redis的原子操作？ 12、讲一下redis的hash操作？ 13、讲一下redis基本数据类型？ 14、讲一下平常用到的设计模式？ 15、讲一下如何实现一个定时任务？ 16、如果rabbitMq中消费者服务挂了，消息堆积高达几千万，你是怎么处理的？ 17、讲讲rabbitMq中订阅模式和消费者模式？ 18、讲下你是如何保证幂等的？ 设计模式 1、用到哪些设计模式？怎么用的 2、单例模式的不同写法 JDK 1、聊一下java的集合类 2、HashMap底层数据结构，以及解决hash碰撞的方法 3、Hashmap为什么要使用红黑树 4、集合类怎么解决高并发问题 5、队列的使用问题 6、自定义异常的应用场景 7、Object类中的方法 8、1.8的新特性 9、Java中的静态方法只有一个实例，如果想用多个实例怎么办？ 10、Java面向对象的基本特征，继承、封装与多态 11、重写和重载是什么意思 12、怎样声明一个类不会被继承 13、HashMap中jdk1.7与jdk1.8的区别 14、concurrenthashMap 的底层实现原理，是如何实现线程安全的？ 15、Java中的自增是线程安全的吗，如何实现线程安全的自增 16、Jdk1.8种的stream有用过吗，stream的并行操作原理，stream并行的线程池是从哪里来的 17、Jdk1.8的completableFuture有用过吗？ 18、Java种的代理有几种实现方式 JVM 1、jvm内存模型，以及这些空间的存放内容 2、堆内存划分的空间，如何回收这些内存对象，有哪些回收算法 3、jvm调优，如何解决线上gc问题 4、class初始化过程 5、内存溢出的原因，如何排查线上问题 6、jvm有哪些垃圾回收器， 7、类加载模型 8、JVM为什么要增加元空间？ 9、堆G1垃圾收集器有了解么，有什么特点 多线程 1、多线程之间是如何通信的 2、synchronized底层实现，和lock的区别 3、synchronized关键字加在静态方法和实例方法的区别 4、countdownlatch的用法 5、线程池 （1）Executor提供了几种线程池 （2）线程池的参数 （3）拒绝策略 （4）任务放置的顺序过程 （5）任务结束后会不会回收线程 （6）未使用的线程池中的线程放在哪里 （7）线程池线程存在哪 （8）cache线程池会不会销毁核心线程 6、Java多线程的几种状态及线程各个状态之间是如何切换的 7、Java中的wait和sleep的区别与联系 8、如何在方法栈中进行数据传递？ 9、ThreadLocal的底层实现形式及实现的数据结构？ 10、Sychornized是否是公平锁 11、Sychronized和ReentryLock的区别 12、服务器CPU数量及线程池数量的关系 mysql 1、Mysql的索引类型，底层索引数据结构，叶子节点存储的是什么，索引失效的原因 2、如何优化sql，查询计划的结果中看哪些些关键数据 3、innodb和myisam的区别 4、mysql默认隔离级别， 5、mysql的乐观锁和悲观锁，锁的种类 6、如何用sql实现乐观锁和悲观锁 7、mysql如何分库分表 8、MySQL为什么选择B+树作为它的存储结构，为什么不选择Hash、二叉、红黑树 9、Mysql数据库的事务与锁的理解 10、数据库临时表有没有用过，是怎么用的？ 11、多数据源情况下如何进行事物的管理 12、Union和union all有什么区别 (如果允许重复的值，请使用 UNION ALL) 13、dateTime和timestamp有什么区别 14、mysql主从模式的实现 15、如何解析sql语句；即explain关键字的使用 16、Mysql的主从同步原理，mysql主从复制主要有几种模式 Spring 1、spring的底层代码， 2、bean的生命周期 3、循环引用问题，以及spring中用到的设计模式 4、spring和springBoot的区别 5、spring的AOP的底层实现原理 6、spring的事务是如何回滚的 7、Spring 是如何解决循环依赖的问题的？ 8、Spring IOC的理解，原理与实现 9、Bean Factory与FactoryBean有什么区别？@Bean这个注解时如何实现Bean的注入的？ Mybatis 1、hibernate的区别 2、mybatis的缓存，都缓存些什么，session缓存存在哪 3、mybatis的执行流程，需要了解源码 4、mybatis如何防止sql注入 redis 1、redis的数据结构类型，一般都用在什么场景下 2、sortedSet的底层数据结构 3、利用redis实现分布式锁 4、redis使用单线程的好处 5、redis中如何控制多线程并发 6、redis删除key的策略 7、redis的主动缓存，被动缓存 8、如何保证数据一致性问题 9、集群环境下如何处理，解释一下一致性哈希 10、解释一下缓存击穿，缓存穿透，缓存雪崩，如何解决这些问题 11、排行榜功能的实现：使用redis的zset；zset的底层数据结构是什么样的；除了redis的zset还有什么其他的数据结构可以实现这个功能 12、Redis集群种类：主从模式、clust"},{"title":"","date":"2021-07-01T08:01:52.101Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"md/面试/日常记录.html","permalink":"https://marchnineteen.github.io/md/%E9%9D%A2%E8%AF%95/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95.html","excerpt":"","text":"需要能力：规划能力，分析能力，设计能力，沟通能力，文档能力，归纳总结能力1.springcloud 微服务大家都怎么用的？1.1用到了哪些技术点？1.2讲讲原理？1.3 和dubbo有啥区别2.zookeeper 和 eureka 有啥区别 满足CAP吗3.mysql为啥用b+树？聚集索引 和非聚集索引的区别4.数据库的锁 有哪几种实现方式 1.mysql a字段建立了索引 between in or 哪个效率高哪个效率低为什么?2.redis 数据分片原理是什么？3.redis 槽坏了一个对集群有啥影响？4.mysql 为什么用b树索引，什么时候用hash索引5.mysql 主从复制从节点失败怎么办？"}],"posts":[{"title":"synchronized&Lock&AQS","slug":"java/coucurrent/synchronized&Lock&AQS","date":"2021-06-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2021/06/08/java/coucurrent/synchronized&Lock&AQS/","link":"","permalink":"https://marchnineteen.github.io/2021/06/08/java/coucurrent/synchronized&Lock&AQS/","excerpt":"","text":"并发同步器多线程编程中，有可能会出现多个线程同时访问同一个共享、可变资源的情况；这种资源可能是：对象、变量、文件等。 共享：资源可以由多个线程同时访问 可变：资源可以在其生命周期内被修改 引出的问题：由于线程执行的过程是不可控的，所以需要采用同步机制来协同对对象可变状态的访问 加锁目的：序列化访问临界资源，即同一时刻只能有一个线程访问临界资源(同步互斥访问) Java锁体系 https://juejin.cn/post/6844904110085373966 synchronized使用与原理加锁方式： 同步实例方法，锁是当前实例对象 同步类方法，锁是当前类对象 同步代码块，锁是括号里面的对象 底层原理: JVM内置锁通过synchronized使用，通过内部对象Monitor(监视器锁)实现，基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock（互斥锁）实现，它是一个重量级锁性能较低 Monitor每个对象都有一个自己的Monitor(监视器锁) JVM加锁过程： 对象内存结构详见jvm认识对象的内存结构： 对象头：比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象）等 对象实际数据：即创建对象时，对象中成员变量，方法等 对齐填充：对象的大小必须是8字节的整数倍 面试问题： 实例对象内存中存储在哪？ 如果实例对象存储在堆区时：实例对象内存存在堆区，实例的引用存在栈上，实例的元数据class存在方法区或者元空间 Object实例对象一定是存在堆区的吗？ 不一定，如果实例对象没有线程逃逸行为 MarkWord以32位JVM中存储内容为例 锁优化升级过程JDK1.6版本之后对synchronized的实现进行了各种优化，如自旋锁、偏向锁和轻量级锁并默认开启偏向锁开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0关闭偏向锁：-XX:-UseBiasedLocking Lock ReentrantLock https://juejin.cn/post/6844903598984282119 ReentrantReadWriteLockAbstractQueuedSynchronizerJava并发编程核心在于java.concurrent.util包而juc当中的大多数同步器实现都是围绕着共同的基础行为，比如等待队列、条件队列、独占获取、共享获取等，而这个行为的抽象就是基于AbstractQueuedSynchronizer简称AQS，AQS定义了一套多线程访问共享资源的同步器框架，是一个依赖状态(state)的同步器。 AQS具备特性 阻塞等待队列 共享/独占 公平/非公平 可重入 允许中断 并发编程包依赖于AQS的内部实现Java.concurrent.util当中同步器的实现如Lock,Latch,Barrier等，都是基于AQS框架实现 一般通过定义内部类Sync继承AQS 将同步器所有调用都映射到Sync对应的方法 AQS框架-管理状态 AQS内部维护属性volatile int state (32位) state表示资源的可用状态 State三种访问方式 getState()、setState()、compareAndSetState() AQS定义两种资源共享方式 Exclusive-独占，只有一个线程能执行，如ReentrantLock Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatch AQS定义两种队列 同步等待队列 条件等待队列 同步队列CLH队列是Craig、Landin、Hagersten三人发明的一种基于双向链表数据结构的队列， 是FIFO先入先出线程等待队列，Java中的CLH队列是原CLH队列的一个变种, 线程由原自旋机制改为阻塞机制。 条件队列Condition是一个多线程间协调通信的工具类，使得某个，或者某些线程一起等待某个条件（Condition）,只有当该条件具备时 ，这些等待线程才会被唤醒，从而重新争夺锁 公平锁 非公平锁 重入锁 不可重入锁","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://marchnineteen.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"JMM&volatile","slug":"java/coucurrent/JMM&volatile","date":"2021-06-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2021/06/08/java/coucurrent/JMM&volatile/","link":"","permalink":"https://marchnineteen.github.io/2021/06/08/java/coucurrent/JMM&volatile/","excerpt":"","text":"现代计算机模型冯诺依曼计算机模型 现代计算机硬件基本结构 CPU内部结构 CPU多核缓存架构 缓存一致性协议(MESI) 具体流程：主存中存在变量x=1，多cpu多线程读取x（lock的是缓存行，当锁的数据横跨多个缓存行时就会进行总线加锁），copy副本到工作线程，此时所有线程中缓存行的状态都是S，T1线程想要修改x时，把缓存行设为E，T1修改x之后，其它线程通过总线嗅探机制时刻监听着，其它线程对该缓存行的操作，发现T1变成M之后，其它线程的变成I，T1对x的操作，等待某一个时间后，刷回主存。其它线程，当发现x被修改之后，会重新去主存中copy，但是cpu不会等待，从而出现指令重排。 线程什么是线程进程是系统分配资源的基本单位，线程是调度CPU的基本单位，一个进程至少包含一个执行线程，线程寄生在进程当中。每个线程都有一个程序计数器（记录要执行的下一条指令），一组寄存器（保存当前线程的工作变量），堆栈（记录执行历史，其中每一帧保存了一个已经调用但未返回的过程） 线程分为两类：用户级线程(User-Level Thread)内核线线程(Kernel-Level Thread) 用户空间划分：内核空间用户空间 Java线程与内核线程的关系 Java线程生命状态 并发为什么用到并发 充分利用多核CPU的计算能力 方便业务拆分，提升应用性能 并发产生的问题 高并发场景下，导致频繁的上下文切换 临界区线程安全问题，容易出现死锁的，产生死锁就会造成系统功能不可用 其它 JMMJMM与JVM内存区域的划分是不同的概念层次，更恰当说JMM描述的是一组规则，通过这组规则控制程序中各个变量在共享数据区域和私有数据区域的访问方式，JMM是围绕原子性，有序性、可见性展开。 简单来说：JMM是计算机CPU多核缓存架构java实现，是一种规则。 JVM虚拟机规范主内存与工作内存 Java内存模型与硬件内存架构的关系JMM模型跟CPU缓存模型结构类似，是基于CPU缓存模型建立起来的，JMM模型是标准化的，屏蔽掉了底层不同计算机的区别。对于硬件内存来说只有寄存器、缓存内存、主内存的概念，并没有工作内存(线程私有数据区域)和主内存(堆内存)之分，也就是说Java内存模型对内存的划分对硬件内存并没有任何影响 Java内存模型内存交互操作1.lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态2.unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定3.read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用4.load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中5.use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎6.assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量7.store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作8.write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 把一个变量从主内存中复制到工作内存中，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。但Java内存模型只要求上述8大操作(原子操作)必须按顺序执行，而没有保证必须是连续执行。 read和load同时出现，store和write同时出现 Java内存模型内存同步规则 volatile原理与内存语义volatile是Java虚拟机提供的轻量级的同步机制 volatile语义有如下两个作用 可见性：保证被volatile修饰的共享变量对所有线程总数可见的，也就是当一个线程修改了一个被volatile修饰共享变量的值，新值总是可以被其他线程立即得知。 有序性：禁止指令重排序优化。 volatile缓存可见性实现原理 JMM内存交互层面：volatile修饰的变量的read、load、use操作和assign、store、write必须是连续的，即修改后必须立即同步会主内存，使用时必须从主内存刷新，由此保证volatile变量的可见性。 底层实现：通过汇编lock前缀指令，它会锁定变量缓存行区域并写回主内存，这个操作称为“缓存锁定”，缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据。一个处理器的缓存回写到内存内存会导致其他处理器的缓存无效 汇编代码查看XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp 可见性&amp;原子性&amp;有序性并发编程三大特性 可见性 原子性 有序性 volatile保证可见性与有序性，但是不能保证原子性，要保证原子性需要借助synchronized、Lock锁机制，同理也能保证有序性与可见性。因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。 有序性&amp;指令重排java语言规范规定JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。 指令重排序的意义：JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性能。 在编译器与CPU处理器中都能执行指令重排优化操作 总线风暴–过度使用volatile可能产生的问题","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://marchnineteen.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}],"tags":[]},{"title":"杭州地铁规划2025","slug":"other/hangzhoumetro2025","date":"2020-04-10T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2020/04/10/other/hangzhoumetro2025/","link":"","permalink":"https://marchnineteen.github.io/2020/04/10/other/hangzhoumetro2025/","excerpt":"","text":"杭州地铁规划2025","categories":[{"name":"other","slug":"other","permalink":"https://marchnineteen.github.io/categories/other/"}],"tags":[]},{"title":"java 1.8  steam流操作","slug":"java/javase/streamApiAction","date":"2020-01-11T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2020/01/11/java/javase/streamApiAction/","link":"","permalink":"https://marchnineteen.github.io/2020/01/11/java/javase/streamApiAction/","excerpt":"","text":"相应源码地址 流操作类型中间操作目的是打开一个流，做出一些操作或者映射后，会返回一个新的流交给下个操作。lazy的，在调用方式时并没有真正执行。 终止操作在执行这个操作后，流被使用，在出现终止操作时才会调用之前的所有方法。 short-circuiting对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。 具体流操作中间操作 map (mapToInt, flatMap 等) 把input Stream 的每一个元素，映射成 output Stream 的另外一个元素。 map一对一 12&#x2F;&#x2F;list中数的平方list.stream().map(v -&gt; v * v) flatMap一对多 多对多 映射,把流扁平化，多个流转化成流里所有元素的单个流。 1234567List&lt;Integer&gt; list1 &#x3D; Arrays.asList(1, 2, 3, 4, 5);List&lt;Integer&gt; list2 &#x3D; Arrays.asList(6, 7, 8, 9, 10);List&lt;List&lt;Integer&gt;&gt; allList &#x3D; new ArrayList&lt;&gt;();allList.add(list1);allList.add(list2); allList.stream().flatMap(v -&gt; v.stream()).forEach(System.out::println); filter 过滤,对元素进行某种条件过滤，留下符合的 12&#x2F;&#x2F; 留下偶数list.stream().filter(v -&gt; v % 2 &#x3D;&#x3D; 0).forEach(System.out::println); distinct 去重，不接收方法 1list.stream().distinct().forEach(System.out::println); sorted 排序，接受一个Comparator，或者默认顺序 12list.stream().sorted()list.stream().sorted((o1, o2) -&gt; -1) peek peek 对每个元素执行操作并返回一个新的 Stream。类似foreach，foreach是终止操作 1list &#x3D; list.stream().peek(System.out::println).collect(Collectors.toList()); limit 返回 Stream 的前面 n 个元素 1list.stream().limit(2).forEach(System.out::println); skip 扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来） 1list.stream().skip(2).forEach(System.out::println); parallel 转行成并行流，进行多线程操作，顺序会改变。可以使用forEachOrdered，固定顺序 123456list.stream().parallel().forEach(System.out::println);34152 sequential 并行流转为串行流 12list.parallelStream().forEach(System.out::println);list.parallelStream().sequential().forEach(System.out::println); unordered 消除了必须保持有序的流的约束,返回一个无序的等效的Stream，可能返回的是Stream本身，因为该Stream已经是无序的，或者该Stream的底层状态被修改为了无序.一般用于并行的时候。例如TreeSet，或者流操作中指定顺序，会取消排序和指定顺序无效。 终止操作 forEach forEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。 forEachOrdered toArray reduce 这个方法的主要作用是把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。从这个意义上说，字符串拼接、数值的 sum、min、max、average 都是特殊的 reduce。 注意：没有起始值，返回对象为Optional collect 两个方法： 1234567891011&lt;R&gt; R collect(Supplier&lt;R&gt; supplier, BiConsumer&lt;R, ? super T&gt; accumulator, BiConsumer&lt;R, R&gt; combiner); IntStream i &#x3D; IntStream.of(6,5,7,1, 2, 3, 3); List&lt;Integer&gt; v &#x3D; i .collect(ArrayList::new, ArrayList::add, ArrayList::addAll); System.out.println(v);&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector); Collector在后面重点讲解 min max count anyMatch allMatch noneMatch findFirst findAny iterator Short-circuiting anyMatch allMatch noneMatch findFirst findAny limit Collectors要作用就是辅助进行各类有用的 reduction 操作，例如转变输出为 Collection，把 Stream 元素进行归组。 类型归纳 12345Collectors.toList();Collectors.toMap();Collectors.toSet();Collectors.toCollection();Collectors.toConcurrentMap(); joining 123456789101112131415List&lt;String&gt; strList = Arrays.asList(\"aa\", \"bb\", \"cc\", \"dd\", \"ee\");String s = strList.stream().collect(Collectors.joining());System.out.println(s);// 逗号连接s = strList.stream().collect(Collectors.joining(\",\"));System.out.println(s);// 逗号连接s = strList.stream().collect(Collectors.joining(\",\", \"[\", \"]\"));System.out.println(s);``` - collectingAndThen```javas = strList.stream().collect(Collectors.collectingAndThen(Collectors.joining(\",\"), String::toUpperCase)); groupingBy groupingByConcurrent 1234Map&lt;Integer, List&lt;String&gt;&gt; map = strList.stream().collect(Collectors.groupingBy(String::length));map.keySet().forEach(v -&gt; map.get(v).forEach(System.out::println)); Map&lt;Integer, Set&lt;String&gt;&gt; map1 = strList.stream().collect(Collectors.groupingBy(String::length, Collectors.toSet(); partitioningBy 12Map&lt;Boolean, List&lt;Integer&gt;&gt; mapBoolean = list.stream().collect(Collectors.partitioningBy(v -&gt; v % 2 == 0));mapBoolean.keySet().forEach(v -&gt; mapBoolean.get(v).forEach(System.out::println)); summingInt/Double/Long summarizingInt/Double/Long","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"秒杀场景","slug":"active/miaosha","date":"2019-12-20T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/12/20/active/miaosha/","link":"","permalink":"https://marchnineteen.github.io/2019/12/20/active/miaosha/","excerpt":"","text":"秒杀场景可能遇到的问题（用户流程角度） 问题一.即将到秒杀时间，同时请求网页过多，打开网页速度慢 问题二.进入页面后，未到秒杀时间，用户一直点击购买按钮，一直发起请求 问题三.用户拿到接口地址，恶意请求（用脚本） 问题四.超卖现象 问题五.数据库请求过多，数据库奔溃 解决方案问题一 针对于动态页面（jsp，ftl）可以把整个页面存储在redis中，避免页面渲染。 前后端分离项目，页面单独部署，使用cdn加速，资源静态 打开网页速度慢，除了页面的原因外，后台请求返回慢也有很大的关系，简单说就是后台高并发能力不足，一遇到此类场景，cpu，内存飚升，程序响应慢。单台tomcat并发量不足，可以集群部署然后使用nginx做负载均衡，恶意请求也可以在此拦截。 后台对请求限流 问题二 页面按钮控制，未到时间按钮不能点击，需要页面定时请求后台获取最新的北京时间，不能以页面本地时间为准 在用户点击过后，再把按钮设置无效，防止无效重复点击 问题三接口地址动态化，通过MD5之类的加密算法加密随机的字符串去做url，然后通过前端代码获取url后台校验才能通过 问题四处理流程：典型的读多先少场景，使用mysql等nosql，把库存存入redis中，进行库存预热。通过三级缓冲保证数据库压力，本地内存标记，库存修改在redis中进行预存，接着通过mq进行异步下单，处理数据库。若下单成功，页面轮询接口返回订单处理状态。 解决超卖方案 防止数据库内存为0，在修改时进行库存判断，大于0才更新。 用户id与商品id建立唯一所以，防止同一用户重复购买同一件商品。 实现乐观锁，商品信息中年增加version字段。每次更新时version+1，更新时候带上版本号，当提交前版本号等于更新前版本号，说明此时没有被其他线程影响到，正常更新，如果冲突了则不会进行提交更新。当库存是足够的情况下发生乐观锁冲突就进行一定次数的重试。 一整套解决方案 产生更多的问题 redis集群，数据同步,分布式锁等 mq高可用 限流&amp;降级&amp;熔断&amp;隔离 分布式服务，事务处理。","categories":[{"name":"active","slug":"active","permalink":"https://marchnineteen.github.io/categories/active/"}],"tags":[]},{"title":"Spring Bean 生命周期","slug":"spring/beanLifeCycle","date":"2019-12-06T00:00:00.000Z","updated":"2021-07-01T08:01:52.085Z","comments":true,"path":"2019/12/06/spring/beanLifeCycle/","link":"","permalink":"https://marchnineteen.github.io/2019/12/06/spring/beanLifeCycle/","excerpt":"","text":"生命周期 单例模式 多例模式需求主动调用才会创建对象，原因见下 1LifeCycle lifeCycle &#x3D; (LifeCycle) applicationContext.getBean(&quot;lifeCycle&quot;); 两者区别单例模式bean在单例模式下，spring容器启动时解析xml文件发现该bean标签后，直接创建该bean对象存入内部map中保存，此后无论调用多少次getBean()获取该bean都是从map中获取该对象返回，一直是一个对象。此对象一直被spring容器持有，直到容器推出时，随着容器的退出对象被销毁。 多例模式bean在多例模式下，spring容器启动时解析xml发下该bean标签后，只是将该bean进行管理，并不会创建对象，此后每层使用getBean()获取该bean时，spring都会重新创建该对象返回，每层都是一个新的对象。这个对象spring容器并不会持有，什么时候销毁却决于该对象的用户自己什么时候销毁该对象。 相应测试源码","categories":[{"name":"spring","slug":"spring","permalink":"https://marchnineteen.github.io/categories/spring/"}],"tags":[]},{"title":"Spring 加载XML文件的六种方式","slug":"spring/springLoadXml","date":"2019-12-06T00:00:00.000Z","updated":"2021-07-01T08:01:52.085Z","comments":true,"path":"2019/12/06/spring/springLoadXml/","link":"","permalink":"https://marchnineteen.github.io/2019/12/06/spring/springLoadXml/","excerpt":"","text":"一: XmlBeanFactory 引用资源1234Resource resource &#x3D; new ClassPathResource(&quot;appcontext.xml&quot;);BeanFactory factory &#x3D; new XmlBeanFactory(resource);BaseEntity entity &#x3D; (BaseEntity) factory.getBean(&quot;baseEntity1&quot;);System.out.println(&quot;XmlBeanFactory 获取 bean ：&quot; + entity.getId()); 二: ClassPathXmlApplicationContext 编译路径123456789&#x2F;&#x2F; 单个文件ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:appcontext.xml&quot;);&#x2F;&#x2F; 多个文件ApplicationContext multiApplicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;classpath:appcontext.xml&quot;, &quot;classpath:appcontext2.xml&quot;);BaseEntity entity &#x3D; (BaseEntity) applicationContext.getBean(&quot;baseEntity&quot;);BaseEntity entity2 &#x3D; (BaseEntity) multiApplicationContext.getBean(&quot;baseEntity2&quot;);System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity.getId());System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean2 ：&quot; + entity2.getId()); 三: 用文件系统的路径123456789101112131415161718&#x2F;&#x2F; classPathApplicationContext fileSystemXmlApplicationContext &#x3D; new FileSystemXmlApplicationContext(&quot;classpath:appcontext.xml&quot;);&#x2F;&#x2F; 文件系统ApplicationContext fileSystemXmlApplicationContext2 &#x3D; new FileSystemXmlApplicationContext(&quot;spring-example-test&#x2F;src&#x2F;main&#x2F;resources&#x2F;appcontext.xml&quot;);ApplicationContext fileSystemXmlApplicationContext3 &#x3D; new FileSystemXmlApplicationContext(&quot;file:E:\\\\marcher\\\\spring-example\\\\spring-example-test\\\\src\\\\main\\\\resources&#x2F;appcontext.xml&quot;);ApplicationContext fileSystemXmlApplicationContext4 &#x3D; new FileSystemXmlApplicationContext(&quot;E:\\\\marcher\\\\spring-example\\\\spring-example-test\\\\src\\\\main\\\\resources&#x2F;appcontext.xml&quot;);BaseEntity entity &#x3D; (BaseEntity) fileSystemXmlApplicationContext.getBean(&quot;baseEntity&quot;);System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity.getId());BaseEntity entity2 &#x3D; (BaseEntity) fileSystemXmlApplicationContext2.getBean(&quot;baseEntity&quot;);System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity2.getId());BaseEntity entity3 &#x3D; (BaseEntity) fileSystemXmlApplicationContext3.getBean(&quot;baseEntity&quot;);System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity2.getId());BaseEntity entity4 &#x3D; (BaseEntity) fileSystemXmlApplicationContext4.getBean(&quot;baseEntity&quot;);System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity2.getId()); 四: XmlWebApplicationContext是专为Web工程定制的。ServletContext servletContext = request.getSession().getServletContext();ApplicationContext ctx = WebApplicationContextUtils.getWebApplicationContext(servletContext ); 五: 使用BeanFactory123456789BeanDefinitionRegistry reg &#x3D; new DefaultListableBeanFactory();XmlBeanDefinitionReader reader &#x3D; new XmlBeanDefinitionReader(reg);reader.loadBeanDefinitions(new ClassPathResource(&quot;appcontext.xml&quot;));reader.loadBeanDefinitions(new ClassPathResource(&quot;appcontext2.xml&quot;));BeanFactory bf &#x3D; (BeanFactory) reg;BaseEntity entity &#x3D; (BaseEntity) bf.getBean(&quot;baseEntity&quot;);BaseEntity entity2 &#x3D; (BaseEntity) bf.getBean(&quot;baseEntity2&quot;);System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity.getId());System.out.println(&quot;ClassPathXmlApplicationContext 获取 bean ：&quot; + entity2.getId()); 六：Web 应用启动时加载多个配置文件通过ContextLoaderListener 也可加载多个配置文件，在web.xml文件中利用元素来指定多个配置文件位置，其配置如下: 12345678910&lt;context-param&gt; &lt;!-- Context Configuration locations for Spring XML files --&gt; &lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt; &lt;param-value&gt; .&#x2F;WEB-INF&#x2F;**&#x2F;Appserver-resources.xml, classpath:config&#x2F;aer&#x2F;aerContext.xml, classpath:org&#x2F;codehaus&#x2F;xfire&#x2F;spring&#x2F;xfire.xml, .&#x2F;WEB-INF&#x2F;**&#x2F;*.spring.xml &lt;&#x2F;param-value&gt; &lt;&#x2F;context-param&gt; 这个方法加载配置文件的前提是已经知道配置文件在哪里，虽然可以利用“*”通配符，但灵活度有限。 获取配套代码","categories":[{"name":"spring","slug":"spring","permalink":"https://marchnineteen.github.io/categories/spring/"}],"tags":[]},{"title":"springmvc整合swagger（非springboot项目）","slug":"日常问题记录/springMVC&swagger","date":"2019-11-27T00:00:00.000Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"2019/11/27/日常问题记录/springMVC&swagger/","link":"","permalink":"https://marchnineteen.github.io/2019/11/27/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/springMVC&swagger/","excerpt":"","text":"项目需求公司原来的项目是struts2，然后想要改成前后端分离项目，又不想完全抛去原来的一些东西，选择了单独的springmvc，没有使用springboot，这就开启了我的难受之旅。 需要依赖万万没想到啊，还不是maven项目，jar包需要自己去探索到底需要哪些jar包，然后还得避免jar包冲突，我太南了…过程中guava库需要升级 jackson库必须存在 最后根据maven项目的所引入的依赖分析，然后自己测试，需要jar包如下： 下载 过程遇到的问题上述过程完成后，好不容易项目启动不报错了，但是访问swagger-ui.html，会出现弹框提示错误，这个错误网上随便一搜就会知道是swagger-ui的页面没有映射出来，需要加个静态资源映射。但是并没有那么简单。 网上搜索大部分搜索出来的都是在xml文件中添加swagger文件的映射，例如： 12&lt;mvc:resources mapping&#x3D;&quot;swagger-ui.html&quot; location&#x3D;&quot;classpath*:&#x2F;META-INF&#x2F;resources&#x2F;&quot;&#x2F;&gt;&lt;mvc:resources mapping&#x3D;&quot;webjars&#x2F;**&quot; location&#x3D;&quot;classpath*:&#x2F;META-INF&#x2F;resources&#x2F;webjars&#x2F;&quot;&#x2F;&gt; 但是在我的工程中没有效果，我也不知道为什么。 解决办法一： 由于项目还是采用web.xml格式配置，dispatcherServlet需拦截所有请求，如果加*.htm这种类型，生成的文档接口也必须手动修改访问路径，因为swagger是根据mapping去生成请求路径的。 这样配置之后静态资源也会访问springMVC的servlet，这是我们不需要的，所以我们需要在springmvc.xml添加mvc:default-servlet-handler/,添加一个默认servlet，会自动过滤静态资源请求。 解决办法二： 去swagger的网站下载zip包，把dist文件目录copy至自己的页面下，修改index.htm文件中的url地址, /v2/api-docs即为swagger访问数据的地址。 1234567891011121314151617181920window.onload &#x3D; function() &#123; &#x2F;&#x2F; Begin Swagger UI call region const ui &#x3D; SwaggerUIBundle(&#123; &#x2F;&#x2F; url: &quot;https:&#x2F;&#x2F;petstore.swagger.io&#x2F;v2&#x2F;swagger.json&quot;, url: &quot;http:&#x2F;&#x2F;xx.xx.xx&#x2F;v2&#x2F;api-docs&quot;, dom_id: &#39;#swagger-ui&#39;, deepLinking: true, presets: [ SwaggerUIBundle.presets.apis, SwaggerUIStandalonePreset ], plugins: [ SwaggerUIBundle.plugins.DownloadUrl ], layout: &quot;StandaloneLayout&quot; &#125;) &#x2F;&#x2F; End Swagger UI call region window.ui &#x3D; ui&#125; 这样添加之后，我们需要去直接访问自己的页面地址，而不是访问swagger-ui.html，例如/swagger/index.html。如果采用.htm或者.do这种方式，可能会出现页面访问得到的，提示/v2/api-docs接口无法请求。解决方案是配置把swagger或者数据的接口置入dispatcherServlet中 1234&lt;servlet-mapping&gt; &lt;servlet-name&gt;SpringmvcDispatcherServlet&lt;&#x2F;servlet-name&gt; &lt;url-pattern&gt;&#x2F;v2&#x2F;api-docs&lt;&#x2F;url-pattern&gt;&lt;&#x2F;servlet-mapping&gt;","categories":[{"name":"日常问题记录","slug":"日常问题记录","permalink":"https://marchnineteen.github.io/categories/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"}],"tags":[]},{"title":"redis","slug":"cache/redis","date":"2019-10-25T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/10/25/cache/redis/","link":"","permalink":"https://marchnineteen.github.io/2019/10/25/cache/redis/","excerpt":"","text":"一、概述（什么是redis）redis是开源免费的key-value内存数据库。 redis可以存储5种数据类型。键只支持string，值支持string，list，map，set，zset五种。 redis支持数据持久化，使用复制来扩展读性能，使用分片来扩展写性能。 二、数据类型 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 对单个或者多个元素进行修剪， 只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名 三、数据结构四、redis应用场景计数器利用string类型可以存储整数和浮点数，进行自增自减操作。 缓存（用的最多的场景）将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 将不经常改变的数据存入缓存，访问频繁访问数据库。 消息队列List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息 不过最好使用 Kafka、RabbitMQ 等消息中间件。 redis 实现 点对点 发布/订阅 消息队列 会话缓存可以使用 Redis 来统一存储多台应用服务器的会话信息。 当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 分布式锁实现在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。 可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它Set 可以实现交集、并集等操作，从而实现共同好友等功能。 ZSet 可以实现有序性操作，从而实现排行榜等功能。 五、数据淘汰策略可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。 Redis 具体有 6 种淘汰策略： 策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。 使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。 Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。 六、持久化RDB 持久化将某个时间点的所有数据都存放到硬盘上。 可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。 如果系统发生故障，将会丢失最后一次创建快照之后的数据。 如果数据量很大，保存快照的时间会很长。 AOF 持久化将写命令添加到 AOF 文件（Append Only File）的末尾。 使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项： 选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。 七、事务一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。 事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。 Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。 通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。 一个从服务器只能有一个主服务器，并且不支持主主复制。 八、复制连接过程 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令； 从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令； 主服务器每执行一次写命令，就向从服务器发送相同的写命令。 主从链随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。 九、SentinelSentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。 十、分片分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。 假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，… ，有不同的方式来选择一个指定的键存储在哪个实例中。 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式： 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。","categories":[{"name":"cache","slug":"cache","permalink":"https://marchnineteen.github.io/categories/cache/"}],"tags":[]},{"title":"缓存概要","slug":"cache/index","date":"2019-10-25T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/10/25/cache/index/","link":"","permalink":"https://marchnineteen.github.io/2019/10/25/cache/index/","excerpt":"","text":"一、缓存特征命中率当某个请求能够通过访问缓存而得到响应时，称为缓存命中。 缓存命中率越高，缓存的利用率也就越高。 最大空间缓存通常位于内存中，内存的空间通常比磁盘空间小的多，因此缓存的最大空间不可能非常大。 当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。 淘汰策略 FIFO（First In First Out）：先进先出策略，在实时性的场景下，需要经常访问最新的数据，那么就可以使用 FIFO，使得最先进入的数据（最晚的数据）被淘汰。 LRU（Least Recently Used）：最近最久未使用策略，优先淘汰最久未使用的数据，也就是上次被访问时间距离现在最久的数据。该策略可以保证内存中的数据都是热点数据，也就是经常被访问的数据，从而保证缓存命中率。 LFU（Least Frequently Used）：最不经常使用策略，优先淘汰一段时间内使用次数最少的数据。 二、LRU以下是基于 双向链表 + HashMap 的 LRU 算法实现，对算法的解释如下： 访问某个节点时，将其从原来的位置删除，并重新插入到链表头部。这样就能保证链表尾部存储的就是最近最久未使用的节点，当节点数量大于缓存最大空间时就淘汰链表尾部的节点。为了使删除操作时间复杂度为 O(1)，就不能采用遍历的方式找到某个节点。HashMap 存储着 Key 到节点的映射，通过 Key 就能以 O(1) 的时间得到节点，然后再以 O(1) 的时间将其从双向队列中删除。 LRU实现 三、CDN内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。 CDN 主要有以下优点： 更快地将数据分发给用户； 通过部署多台服务器，从而提高系统整体的带宽性能； 多台服务器可以看成是一种冗余机制，从而具有高可用性。 四、缓存问题缓存穿透指对某一个一定不存在的数据进行请求，该请求会将穿透缓存到达数据库。 解决方案： 对这些不存在的数据缓存一个空数据 对这类请求进行过滤 缓存雪崩指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。 在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。 解决方案： 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。 缓存一致性缓存一致性要求数据更新的同时缓存数据也能够实时更新。 解决方案： 在数据更新的同时立即去更新缓存； 在读缓存之前先判断缓存是否是最新的，如果不是最新的先进行更新。 缓存 “无底洞” 现象指的是为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。 产生原因：缓存系统通常采用 hash 函数将 key 映射到对应的缓存节点，随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作，这意味着批量操作的耗时会随着节点数目的增加而不断增大。此外，网络连接数变多，对节点的性能也有一定影响。 解决方案： 优化批量数据操作命令； 减少网络通信次数； 降低接入成本，使用长连接 / 连接池，NIO 等。 五、数据分布哈希分布哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。例如有 N 个节点，数据的主键为 key，则将该数据分配的节点序号为：hash(key)%N。 传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。 顺序分布将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。例如 User 表的 ID 范围为 1 ~ 7000，使用顺序分布可以将其划分成多个子表，对应的主键范围为 1 ~ 1000，1001 ~ 2000，…，6001 ~ 7000。 顺序分布相比于哈希分布的主要优点如下： 能保持数据原有的顺序； 并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。 六、一致性哈希Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。 基本原理将哈希空间 [0, 2n-1] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。 一致性哈希在增加或者删除节点时只会影响到哈希环中相邻的节点，例如下图中新增节点 X，只需要将它前一个节点 C 上的数据重新进行分布即可，对于节点 A、B、D 都没有影响。 虚拟节点上面描述的一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同。 数据不均匀主要是因为节点在哈希环上分布的不均匀，这种情况在节点数量很少的情况下尤其明显。 解决方式是通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。","categories":[{"name":"cache","slug":"cache","permalink":"https://marchnineteen.github.io/categories/cache/"}],"tags":[]},{"title":"webXml和spring初始化顺序问题","slug":"日常问题记录/webXml和spring初始化顺序问题","date":"2019-10-17T00:00:00.000Z","updated":"2021-07-01T08:01:52.101Z","comments":true,"path":"2019/10/17/日常问题记录/webXml和spring初始化顺序问题/","link":"","permalink":"https://marchnineteen.github.io/2019/10/17/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/webXml%E5%92%8Cspring%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98/","excerpt":"","text":"问题产生同事想要在项目初始化完成后，开启线程池执行业务逻辑的代码，其中需要注入spring的bean，他想到使用servlet的listener，但是无法在listener中无法直接通过@Resource注解获取实例。 原因分析在tomcat容器中，listener，filter，servlet等都不是交给spring容器管理，两者环境不一致当然就获取不到了。 问题解决如果需要在tomcat等web容器环境中获取spring实例需要获取ServletContext，通过webContext去获取springIOC容器从而获取spring实例。 12345678910&#x2F;&#x2F;ServletContext,是一个全局的储存信息的空间，服务器开始，其就存在，服务器关闭，其才释放。request，一个用户可有多个；session，一个用户一个；而servletContext，所有用户共用一个。&#x2F;&#x2F;所以，为了节省空间，提高效率，ServletContext中，要放必须的、重要的、所有用户需要共享的线程又是安全的一些信息。 @Override public void contextInitialized(ServletContextEvent servletContextEvent) &#123; WebApplicationContext springContext &#x3D; WebApplicationContextUtils.getWebApplicationContext(servletContextEvent.getServletContext()); Init init &#x3D; (Init) springContext.getBean(&quot;Init&quot;); System.out.println(init); System.out.println(&quot;listener init&quot;); &#125; 问题延伸web.xml文件中各个节点参数的启动顺序可以明确的是初始化顺序context-param -&gt; listener-&gt; filter -&gt; servlet。 在代码中分别自定义listener，filter，spring bean（Init）。启动项目可以看出先打印 listener init,再打印filter init。 那么spring容器的bean呢，在什么时候会进行初始化。新建Init类实现InitializingBean，然后在xml中配置该bean，这样spring容器初始化是会去执行afterPropertiesSet方法。 1234@Override public void afterPropertiesSet() throws Exception &#123; System.out.println(&quot;InitializingBean&quot;); &#125; 创建完java文件后，咱们先来看看 web.xml。 一般springIOC容器在context-param进行初始化，此时spring就已经在初始化xml文件中的实例了。 1234567&lt;!--在web.xml中通过contextConfigLocation配置spring，contextConfigLocation--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt; &lt;param-value&gt; classpath:spring-context.xml &lt;&#x2F;param-value&gt; &lt;&#x2F;context-param&gt; spring的xml其实也可以放在其它地方进行加载，比如说listener，servlet中，例如springMVC的xml文件，会配置在servlet中，进行路由转发。 1234567891011121314&lt;!-- 请求转发器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;&#x2F;servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;&#x2F;servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;&#x2F;param-value&gt; &lt;&#x2F;init-param&gt; &lt;load-on-startup&gt;1&lt;&#x2F;load-on-startup&gt; &lt;&#x2F;servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;&#x2F;servlet-name&gt; &lt;url-pattern&gt;&#x2F;&lt;&#x2F;url-pattern&gt; &lt;&#x2F;servlet-mapping&gt; 如若此时在contextConfigLocation下增加classpath:spring-context.xml，spring同样也会去初始化配置文件。所以可以得出结论，springIOC环境的初始化与web context的初始化顺序无直接关联。 那么问题来了，在listener，filter中获取WebApplicationContext可以获得spring bean吗？ 我们先把spring-context.xml放在context-param中，让它在lister之前进行spring初始化，看看效果 1234567891011121314151617 修改xml文件 &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt; &lt;param-value&gt; classpath:spring-context.xml &lt;&#x2F;param-value&gt; &lt;&#x2F;context-param&gt; 修改自定义CustomListener @Override public void contextInitialized(ServletContextEvent servletContextEvent) &#123; WebApplicationContext springContext &#x3D; WebApplicationContextUtils.getWebApplicationContext(servletContextEvent.getServletContext()); Init init &#x3D; (Init) springContext.getBean(&quot;init&quot;); System.out.println(init); System.out.println(&quot;listener init&quot;); &#125; 此时InitializingBean最先打印出来，说明其在listener，filter之前执行了。控制台输出 com.wyb.web.config.Init@e082c17，说明在listen之前，spring的Context已经初始化，可以获取到bean，那么我们把spring-context.xml放在servlet中去初始化，即在listener之后初始化会怎么样呢？ 修改web.xml代码 12345678910111213&lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;&#x2F;servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;&#x2F;servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;&#x2F;param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml,classpath:spring-context.xml&lt;&#x2F;param-value&gt; &lt;&#x2F;init-param&gt; &lt;load-on-startup&gt;1&lt;&#x2F;load-on-startup&gt; &lt;&#x2F;servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;&#x2F;servlet-name&gt; &lt;url-pattern&gt;&#x2F;&lt;&#x2F;url-pattern&gt; &lt;&#x2F;servlet-mapping&gt; 此时InitializingBean最后打印，说明其在listener，filter之后执行了。CustomListener抛出NoSuchBeanDefinitionException异常，即无法获得该实例，由此得出结论，spring bean的初始化顺序由配置文件在web.xml中什么时候加载有关，与listener，filter无直接关系。若listener想获得spring bean，该bean需要在listener之前进行初始化。 两个spring bean之间进行相互注入依赖，则要看xml文件在web.xml进行加载的顺序。绝对了spring bean初始化的顺序。","categories":[{"name":"日常问题记录","slug":"日常问题记录","permalink":"https://marchnineteen.github.io/categories/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"}],"tags":[]},{"title":"git常用指令","slug":"tool/git常用指令","date":"2019-08-27T00:00:00.000Z","updated":"2021-07-01T08:01:52.085Z","comments":true,"path":"2019/08/27/tool/git常用指令/","link":"","permalink":"https://marchnineteen.github.io/2019/08/27/tool/git%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/","excerpt":"","text":"工作区与暂存区 版本回退： 1234git log (git log --pretty&#x3D;oneline) 查看提交日志git log --graph --pretty&#x3D;oneline --abbrev-commit 简化查看日志git reset --hard commitid(HEAD^ HEAD表示当前版本 ^表示上个版本 以此类推,也可以使用~num,num表示几个^) (windows命令行下需要git reset --hard &quot;HEAD^&quot; ) git reflog 查看命令历史 管理修改： 12345git add xx 把文件添加到版本库git status 查看当前版本库状态git commit -m &quot;msg&quot; 提交修改 -m表示提交注释 ps:若使用命令行提交，每次commit都需addgit diff git diff HEAD -- xx.file 查看工作区和版本库里面最新版本的区别 (HEAD^ 与版本回退同理) 撤销修改： 123git checkout -- xx 把文件在工作区的修改全部撤销。第一种情况修改后未被放入暂存区，撤销修改与版本库一致，第二种已经添加到了暂存区，又作了修改，撤销修改回到add时的状态。让这个文件回到最近一次git commit或git add时的状态git reset HEAD &lt;file&gt; 把暂存区的修改回退到工作区,适用于add未commit 删除文件： 1git rm 用于删除一个文件 取消文件跟踪： 123git rm --cached xx.txt 删除readme1.txt的跟踪，并保留在本地。之后git commit git rm --f xx.txt 删除readme1.txt的跟踪，并且删除本地文件。之后git commit 远程仓库 添加远程库： 123git remote add origin xx.git 添加远程仓库地址git push -u origin master 由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令git push origin master推送最新修改 从远程库克隆： 1git clone xx.git 多人协作： 1234567git remote -v 查看远程库信息git fetch origin &lt;branch-name&gt; 从远程拉去分支代码git merge 合并代码git pull &#x3D; git fetch + git mergegit push origin &lt;branch-name&gt; 推送修改git checkout -b &lt;branch-name&gt; origin&#x2F;&lt;branch-name&gt; 本地创建和远程分支对应的分支,名称最好一致git branch --set-upstream &lt;branch-name&gt; origin&#x2F;&lt;branch-name&gt; 建立本地分支和远程分支的关联 git放弃本地修改，强制更新： 123git fetch --all 下载远程仓库最新内容，不做合并git reset --hard origin&#x2F;master 把HEAD指向master最新版本git pull 分支管理 创建与合并分支： 123456git branch dev 创建dev分支git checkout dev 切换至dev分支git checkout -b dev 创建并切换至dev分支git branch 查看当前分支git merge dev 合并dev分支代码至当前分支git branch -d dev 删除dev分支 解决冲突： 1git log --graph 命令可以看到分支合并图 Bug分支： 123456git stash 暂存当前工作区代码git stash list 查看暂存代码记录git stash apply 恢复代码至工作区，但不删除暂存内容git stash drop 删除暂存内容git stash pop &#x3D; git stash apply + git stash drop 恢复代码至工作区并删除暂存内容git cherry-pick &lt;commitid&gt; 复制某一次提交代码至当前分支 标签管理 创建标签： 1234git tag &lt;tagname&gt; 用于新建一个标签，默认为HEAD，也可以指定一个commit idgit tag -a &lt;tagname&gt; -m &quot;msg&quot; 可以指定标签信息git tag 查看所有标签git show &lt;tagname&gt; 查看说明 操作标签： 1234git tag -d &lt;tagname&gt; 删除一个本地标签git push origin :refs&#x2F;tags&#x2F;&lt;tagname&gt; 删除一个远程标签git push origin &lt;tagname&gt; 推送标签至远程git push origin --tags 一次性推送全部尚未推送到远程的本地标签","categories":[{"name":"tool","slug":"tool","permalink":"https://marchnineteen.github.io/categories/tool/"}],"tags":[]},{"title":"maven-dependence","slug":"tool/maven-dependence","date":"2019-05-30T00:00:00.000Z","updated":"2021-07-01T08:01:52.085Z","comments":true,"path":"2019/05/30/tool/maven-dependence/","link":"","permalink":"https://marchnineteen.github.io/2019/05/30/tool/maven-dependence/","excerpt":"","text":"scope参数在dependence中表示依赖的范围。首先需要知道，maven在编译项目主代码的时候需要使用一套classpath。例如在编译项目主代码的时候需要用到spring-core，该文件以依赖的方式被引入到classpath中。其次，maven在编译和执行测试的时候会使用另一套classpath，Junit就是一个很好的例子，该文件也以依赖的方式引入到测试使用的classpath中，不同的是这里的依赖范围是test。最后，实际运行maven项目的时候，又会使用一套classpath。 依赖范围就是用来控制依赖与这三种classpath（编辑classpath、测试classpath、运行classpath）的关系，maven有以下几种依赖范围： Compile：编译依赖范围。如果没有指定，就会默认使用该依赖范围。使用此依赖范围的maven依赖，对于编译、测试、运行三种classpath都有效。典型的例子是spring-core，在编译、测试和运行的时候都需要使用该依赖。 Test：测试依赖范围。使用此依赖范围的maven依赖，只对于测试的classpath有效，在编译主代码或者运行项目的使用时将无法使用此类依赖。典型的例子是Junit，它只有在编辑测试代码及运行测试的时候才需要。 Provided：已提供依赖范围。使用此依赖范围的maven依赖，对于编译和测试classpath有效，但在运行时无效。典型的例子是servlet-api，编译和测试项目的时候需要该依赖，但在运行项目的时候，由于容器已经提供，就不需要maven重复的引入一遍。 Runtime：运行时依赖范围。使用该依赖范围的maven依赖，对于测试和运行classpath有效，但在编译主代码时无效。典型的例子是JDBC驱动实现，项目主代码的编译只需要JDK提供的JDBC接口，只有在执行测试或者运行项目的时候才需要实现上述的具体JDBC驱动。 System：系统依赖范围。该依赖与三种classpath的关系，和Provided依赖范围完全一致。但是，使用System范围的依赖是必须通过systemPath元素显示地指定依赖文件的路径。由于此类依赖不是通过maven仓库解析的，而且往往与本机的系统绑定，可能造成构建的不可移植，因此应该谨慎使用。systemPath元素可以引用环境变量，如： &lt;dependency&gt; &lt;groupId&gt;java.sql&lt;/groupId&gt; &lt;artifactId&gt;jdbc-stdext&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;${java.home}/lib/rt.jar&lt;/systemPath&gt; &lt;/dependency&gt;Import(maven2.0.9及以上)：导入依赖范围。该依赖范围不会对3中classpath产生实际影响。 上述出import依赖的各种依赖范围3中classpath的关系如下表： 依赖范围(scope) 编译classpath有效 测试classpath有效 运行classpath有效 例子 compile Y Y Y spring-core test - Y - junit provided Y Y - servlet-api runtime - Y Y JDBC驱动 system Y Y - 本地的，maven仓库之外的类库文件 maven传递性依赖传递性依赖和依赖范围： 依赖范围不仅可以控制依赖与三种classpath的关系，还对传递性依赖产生影响。例，account-email对于spring-core的依赖范围是compile，spring-core对于commons-logging的依赖范围的是compile，那么account-email对于commons-logging这一传递依赖的范围也及时compile。假设A依赖与B，B依赖与C，我们说A对于B的依赖是第一直接依赖，B对于C的依赖为第二直接依赖，A对于C是传递性依赖。第一直接依赖的范围是和第二直接依赖的范围决定了传递性依赖的范围，如下表所示，最左边一行表示第一直接依赖范围，最上面一行便是第二直接依赖范围，中间的交叉单元格则便是传递性依赖范围: compile test provided runtime compile compile - - runtime test test - - test provided provided - provided provided runtime runtime - - runtime 仔细观察表格，可以发现规律：当第二直接依赖为compile的时候，传递性依赖的范围与第一直接依赖范围一致；当第二直接依赖范围是test的时候，依赖不会得以传递，当第二直接依赖的范围是provided的时候，只传递第一直接依赖范围也为provided的依赖，且传递性依赖的范围同样为provided；当第二传递依赖是runtime的时候，传递性依赖的范围与第一直接依赖的范围一致，丹compile例外，此时传递性依赖的范围为runtime。 maven可选依赖使用元素表示依赖为可选依赖，只会对当前项目产生影响，当其他项目依赖当前项目时，该依赖不会被传递","categories":[{"name":"tool","slug":"tool","permalink":"https://marchnineteen.github.io/categories/tool/"}],"tags":[]},{"title":"sql优化","slug":"database/sqlOptimization","date":"2019-04-12T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/04/12/database/sqlOptimization/","link":"","permalink":"https://marchnineteen.github.io/2019/04/12/database/sqlOptimization/","excerpt":"","text":"SQLOptimizationTree SQL优化技术 1) 最左前缀法则 2）在索引列上做类型转换，函数变换等操作 3）存储引擎不能使用范围条件右边的列作为索引 5）!= , > , = (SELECT id FROM table LIMIT 1000000, 1) LIMIT 10; 是的，速度提升到0.x秒了，看样子还行了 可是，还不是完美的！ 以下这句才是完美的！ SELECT * FROM table WHERE id BETWEEN 1000000 AND 1000010; 比上面那句，还要再快5至10倍 从中我们也能总结出两件事情： 1）limit语句的查询时间与起始记录的位置成正比 2）mysql的limit语句是很方便，但是对记录很多的表并不适合直接使用。 2.对limit分页问题的性能优化方法 利用表的覆盖索引来加速分页查询 我们都知道，利用了索引查询的语句中如果只包含了那个索引列（覆盖索引），那么这种情况会查询很快。 因为利用索引查找有优化算法，且数据就在查询索引上面，不用再去找相关的数据地址了，这样节省了很多时间。另外Mysql中 也有相关的索引缓存，在并发高的时候利用缓存就效果更好了。 另外，如果需要查询 id 不是连续的一段，最佳的方法就是先找出 id ，然后用 in 查询 SELECT * FROM table WHERE id IN(10000, 100000, 1000000...); 再分享一点 查询字段一较长字符串的时候，表设计时要为该字段多加一个字段,如，存储网址的字段 查询的时候，不要直接查询字符串，效率低下，应该查诡该字串的crc32或md5。 在我们的例子中，我们知道id字段是主键，自然就包含了默认的主键索引。现在让我们看看利用覆盖索引的查询效果如何： 这次我们之间查询最后一页的数据（利用覆盖索引，只包含id列），如下： select id from order limit 800000, 20 0.2秒 相对于查询了所有列的37.44秒，提升了大概100多倍的速度 那么如果我们也要查询所有列，有两种方法，一种是id>=的形式，另一种就是利用join，看下实际情况： SELECT * FROM order WHERE ID > =(select id from order limit 800000, 1) limit 20 查询时间为0.2秒，简直是一个质的飞跃啊，哈哈 另一种写法 SELECT * FROM order a JOIN (select id from order limit 800000, 20) b ON a.ID = b.id 查询时间也很短 查询锁表信息 当前运行的所有事务 select * from information_schema.innodb_trx 当前出现的锁 select * from information_schema.innodb_locks 锁等待的对应关系 select * from information_schema.innodb_lock_waits Mysql一次插入几万条数据处理方式 1）Insert批量插入，调整max_allowed_packet 2) 开启事务，增大innodb_log_buffer_size，增加单事务提交日志量。 3）主键顺序插入，效率更高 5）对要插入的数据进行分组批量插入 INSERT INTO table (column1, column2, ..., column_n) VALUES (value11, value12, ..., value1n), (value21, value22, ... value2n), ..., (value_n1, value_n2, ... value_nn) 常用的插入语句如： INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0); INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('1', 'userid_1', 'content_1', 1); 修改成： INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1); 修改后的插入操作能够提高程序的插入效率。这里第二种SQL执行效率高的主要原因是合并后日志量（MySQL的binlog和innodb的事务让 日志）减少了，降低日志刷盘的数据量和频率，从而提高效率。通过合并SQL语句，同时也能减少SQL语句解析的次数，减少网络传 输的IO。 数据有序插入。 数据有序的插入是指插入记录在主键上是有序排列，例如datetime是记录的主键： INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('1', 'userid_1', 'content_1', 1); INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0); INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('2', 'userid_2', 'content_2',2); 修改成： INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0); INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('1', 'userid_1', 'content_1', 1); INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('2', 'userid_2', 'content_2',2); 由于数据库插入时，需要维护索引数据，无序的记录会增大维护索引的成本。我们可以参照InnoDB使用的B+tree索引，如果每次插 入记录都在索引的最后面，索引的定位效率很高，并且对索引调整较小；如果插入的记录在索引中间，需要B+tree进行分裂合并等 处理，会消耗比较多计算资源，并且插入记录的索引定位效率会下降，数据量较大时会有频繁的磁盘操作。 从测试结果来看，该优化方法的性能有所提高，但是提高并不是很明显。 SQL语句是有长度限制，在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packet配置可以修改，默认是1M， 测试时修改为8M。 事务需要控制大小，事务太大可能会影响执行的效率。MySQL有innodb_log_buffer_size配置项，超过这个值会把innodb的数据刷到 磁盘中，这时，效率会有所下降。所以比较好的做法是，在数据达到这个这个值前进行事务提交。 Mysql配置优化提高SQL查询写入性能 提高数据库插入性能的中心思想： 1）尽量将数据一次性写入到Data File 2）减少数据库的checkpoint 操作 innodb_buffer_pool_size 如果用Innodb，那么这是一个重要变量。相对于MyISAM来说，Innodb对于 buffer size更敏感。MySIAM可能对于大数据量使用默认的key_buffer_size也还好， 但Innodb在大数据量时用默认值就感觉在爬了。 Innodb的缓冲池会缓存数据和索引，所 以不需要给系统的缓存留空间，如果只用Innodb，可以把这个值设为内存的70%-80%。 和 key_buffer相同，如果数据量比较小也不怎么增加，那么不要把这个值设太高也可以提 高内存的使用率。 innodb_log_file_size 此配置项作用设定innodb 数据库引擎UNDO日志的大小；从而减少数据库checkpoint 操作。 对于写很多尤其是大数据量时非常重要。要注意，大的文件提供更高的性能，但数据库恢 复时会用更多的时间。我一般用64M-512M，具体取决于服务器的空间。 innodb_log_buffer_size 此配置项作用设定innodb 数据库引擎写日志缓存区；将此缓存段增大可以减少数据库写 数据文件次数 默认值对于多数中等写操作和事务短的运用都是可以的。如 果经常做更新或者使用了 很多blob数据，应该增大这个值。但太大了也是浪费内存，因为1秒钟总会 flush（这个词 的中文怎么说呢？）一次，所以不需要设到超过1秒的需求。8M-16M一般应该够了。小的运用 可以设更小一点。 innodb_flush_log_at_trx_commit 0: Write the log buffer to the log file and flush the log file every second, but do nothing at transaction commit. 1：the log buffer is written out to the log file at each transaction commit and the flush to disk operation is performed on the log file 2：the log buffer is written out to the file at each commit, but the flush to disk operation is not performed on it 抱怨Innodb比MyISAM慢 100倍？那么你大概是忘了调整这个值。默认值1的意思是每一 次事务提交或事务外的指令都需要把日志写入（flush）硬盘，这是很费时的。特别是使用 电 池供电缓存（Battery backed up cache）时。设成2对于很多运用，特别是从MyISAM 表转过来的是可以的，它的意思是不写入硬盘而是写入系统缓存。日志仍然会每秒flush到 硬 盘，所以你一般不会丢失超过1-2秒的更新。设成0会更快一点，但安全方面比较差，即 使MySQL挂了也可能会丢失事务的数据。而值2只会在整个操作系统 挂了时才可能丢数据。 innodb_autoextend_increment 配置由于默认8M 调整到 128M 此配置项作用主要是当tablespace 空间已经满了后，需要MySQL系统需要自动扩展多 少空间，每次tablespace 扩展都会让各个SQL 处于等待状态。增加自动扩展Size可以减 少tablespace自动扩展次数。 提高数据库插入性能中心思想： 1、尽量使数据库一次性写入Data File 2、减少数据库的checkpoint 操作 3、程序上尽量缓冲数据，进行批量式插入与提交 4、减少系统的IO冲突 提高数据库读取速度 Mysql表查询优化经验 Using index 查询的列被索引覆盖，并且where筛选条件是索引的是前导列 Using where Using index 1:查询的列被索引覆盖，并且where筛选条件是索引列之一但是不是索引的不是前导列， Extra中为Using where; Using index，意味着无法直接通过索引查找来查询到符 合条件的数据 2:查询的列被索引覆盖，并且where筛选条件是索引列前导列的一个范围，同样意味着无法 直接通过索引查找查询到符合条件的数据 NULL（既没有Using index，也没有Using where Using index，也没有using where） 1，查询的列未被索引覆盖，并且where筛选条件是索引的前导列， 意味着用到了索引，但是部分字段未被索引覆盖，必须通过“回表”来实现，不是纯粹地用 到了索引，也不是完全没用到索引，Extra中为NULL(没有信息) Using where 1，查询的列未被索引覆盖，where筛选条件非索引的前导列，Extra中为Using where 2，查询的列未被索引覆盖，where筛选条件非索引列，Extra中为Using where using where 意味着通过索引或者表扫描的方式进程where条件的过滤， 反过来说，也就是没有可用的索引查找，当然这里也要考虑索引扫描+回表与表扫描的代价。 这里的type都是all，说明MySQL认为全表扫描是一种比较低的代价。 Using index condition 1，-- 查询的列不全在索引中，where条件中是一个前导列的范围 2，查询列不完全被索引覆盖，查询条件完全可以使用到索引（进行索引查找） Explain详细解析 table：表名 type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、 eq_reg、ref、range、index和ALL possible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关 的域从WHERE语句中选择一个合适的语句 key： 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MYSQL会选择优化不足 的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使 用一个索引或者用IGNORE INDEX（indexname）来强制MYSQL忽略索引 key_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好 ref：显示索引的哪一列被使用了，如果可能的话，是一个常数 rows：MYSQL认为必须检查的用来返回请求数据的行数 extra列返回的描述的意义 Distinct:一旦MYSQL找到了与行相联合匹配的行，就不再搜索了 Not exists: MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行，就不 再搜索了 Range checked for each Record（index map:#）:没有找到理想的索引，因此对 于从前面表中来的每一个行组合，MYSQL检查使用哪个索引，并用它来从表中 返回行。这是使用索引的最慢的连接之一 Using filesort: 看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来 发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行 的行指针来排序全部行 Using index: 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返 回的，这发生在对表的全部的请求列都是同一个索引的部分的时候 Using temporary 看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时 表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上 Where used 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果 不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有 问题不同连接类型的解释（按照效率高低的顺序排序） system 表只有一行：system表。这是const连接类型的特殊情况 const:表中的一个记录的最大值能够匹配这个查询（索引可以是主键或惟一索引）。因 为只有一行，这个值实际就是常数，因为MYSQL先读这个值然后把它当做常数来对待 eq_ref:在连接中，MYSQL在查询时，从前面的表中，对每一个记录的联合都从表中读取 一个记录，它在查询使用了索引为主键或惟一键的全部时使用 ref:这个连接类型只有在查询使用了不是惟一或主键的键或者是这些类型的部分 （比如，利用最左边前缀）时发生。对于之前的表的每一个行联合，全部记录都将从 表中读出。这个类型严重依赖于根据索引匹配的记录多少—越少越好 range:这个连接类型使用索引返回一个范围中的行，比如使用>或","categories":[{"name":"database","slug":"database","permalink":"https://marchnineteen.github.io/categories/database/"}],"tags":[]},{"title":"数据库系统原理(转载)","slug":"database/数据库系统原理","date":"2019-04-12T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/04/12/database/数据库系统原理/","link":"","permalink":"https://marchnineteen.github.io/2019/04/12/database/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86/","excerpt":"","text":"原文 一、事务 概念 ACID AUTOCOMMIT 二、并发一致性问题 丢失修改 读脏数据 不可重复读 幻影读 三、封锁 封锁粒度 封锁类型 封锁协议 MySQL 隐式与显示锁定 四、隔离级别 未提交读（READ UNCOMMITTED） 提交读（READ COMMITTED） 可重复读（REPEATABLE READ） 可串行化（SERIALIZABLE） 五、多版本并发控制 版本号 隐藏的列 Undo 日志 实现过程 快照读与当前读 六、Next-Key Locks Record Locks Gap Locks Next-Key Locks 七、关系数据库设计理论 函数依赖 异常 范式 八、ER 图 实体的三种联系 表示出现多次的关系 联系的多向性 表示子类 参考资料 一、事务概念事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 ACID1. 原子性（Atomicity）事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。 回滚可以用回滚日志来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。 2. 一致性（Consistency）数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。 3. 隔离性（Isolation）一个事务所做的修改在最终提交以前，对其它事务是不可见的。 4. 持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。 使用重做日志来保证持久性。 事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系： 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 AUTOCOMMITMySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询都会被当做一个事务自动提交。 二、并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。 丢失修改T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。 读脏数据T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 不可重复读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 幻影读T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 三、封锁封锁粒度MySQL 中提供了两种封锁粒度：行级锁以及表级锁。 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。 在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。 封锁类型1. 读写锁 排它锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定： 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下： - X S X × × S × √ 2. 意向锁使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。 在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。 意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定： 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。 各种锁的兼容关系如下： - X IX S IS X × × × × IX × √ × √ S × × √ √ IS × √ √ √ 解释如下： 任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁； S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。 封锁协议1. 三级封锁协议一级封锁协议 事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。 可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 T1 T2 lock-x(A) read A=20 lock-x(A) wait write A=19 . commit . unlock-x(A) . obtain read A=19 write A=21 commit unlock-x(A) 二级封锁协议 在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。 可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 T1 T2 lock-x(A) read A=20 write A=19 lock-s(A) wait rollback . A=20 . unlock-x(A) . obtain read A=20 unlock-s(A) commit 三级封锁协议 在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。 可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 T1 T2 lock-s(A) read A=20 lock-x(A) wait read A=20 . commit . unlock-s(A) . obtain read A=20 write A=19 commit unlock-X(A) 2. 两段锁协议加锁和解锁分为两个阶段进行。 可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。 事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。 1lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B) 但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度。 1lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C) MySQL 隐式与显示锁定MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。 InnoDB 也可以使用特定的语句进行显示锁定： 12SELECT ... LOCK In SHARE MODE;SELECT ... FOR UPDATE; 四、隔离级别未提交读（READ UNCOMMITTED）事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED）一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ）保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化（SERIALIZABLE）强制事务串行执行。 隔离级别 脏读 不可重复读 幻影读 加锁读 未提交读 √ √ √ × 提交读 × √ √ × 可重复读 × × √ × 可串行化 × × × √ 五、多版本并发控制多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。 版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号： 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Undo 日志MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。 实现过程以下实现过程针对可重复读隔离级别。 当开始新一个事务时，该事务的版本号肯定会大于当前所有数据行快照的创建版本号，理解这一点很关键。 1. SELECT多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于 T 的版本号，因为如果大于或者等于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须大于 T 的版本号，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。 2. INSERT将当前系统版本号作为数据行快照的创建版本号。 3. DELETE将当前系统版本号作为数据行快照的删除版本号。 4. UPDATE将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为先执行 DELETE 后执行 INSERT。 快照读与当前读1. 快照读使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。 1select * from table ...; 2. 当前读读取的是最新的数据，需要加锁。以下第一个语句需要加 S 锁，其它都需要加 X 锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert;update;delete; 六、Next-Key LocksNext-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。 MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。 Record Locks锁定一个记录上的索引，而不是记录本身。 如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。 1SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; Next-Key Locks它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间： 12345(negative infinity, 10](10, 11](11, 13](13, 20](20, positive infinity) 七、关系数据库设计理论函数依赖记 A-&gt;B 表示 A 函数决定 B，也可以说 B 函数依赖于 A。 如果 {A1，A2，… ，An} 是关系的一个或多个属性的集合，该集合函数决定了关系的其它所有属性并且是最小的，那么该集合就称为键码。 对于 A-&gt;B，如果能找到 A 的真子集 A’，使得 A’-&gt; B，那么 A-&gt;B 就是部分函数依赖，否则就是完全函数依赖。 对于 A-&gt;B，B-&gt;C，则 A-&gt;C 是一个传递函数依赖。 异常以下的学生课程关系的函数依赖为 Sno, Cname -&gt; Sname, Sdept, Mname, Grade，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 不符合范式的关系，会产生很多异常，主要有以下四种异常： 冗余数据：例如 学生-2 出现了两次。 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 课程-1 需要删除第一行和第三行，那么 学生-1 的信息就会丢失。 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。 范式范式理论是为了解决以上提到四种异常。 高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。 1. 第一范式 (1NF)属性不可分。 2. 第二范式 (2NF)每个非主属性完全函数依赖于键码。 可以通过分解来满足。 分解前 Sno Sname Sdept Mname Cname Grade 1 学生-1 学院-1 院长-1 课程-1 90 2 学生-2 学院-2 院长-2 课程-2 80 2 学生-2 学院-2 院长-2 课程-1 100 3 学生-3 学院-2 院长-2 课程-2 95 以上学生课程关系中，{Sno, Cname} 为键码，有如下函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname Sno, Cname-&gt; Grade Grade 完全函数依赖于键码，它没有任何冗余数据，每个学生的每门课都有特定的成绩。 Sname, Sdept 和 Mname 都部分依赖于键码，当一个学生选修了多门课时，这些数据就会出现多次，造成大量冗余数据。 分解后 关系-1 Sno Sname Sdept Mname 1 学生-1 学院-1 院长-1 2 学生-2 学院-2 院长-2 3 学生-3 学院-2 院长-2 有以下函数依赖： Sno -&gt; Sname, Sdept Sdept -&gt; Mname 关系-2 Sno Cname Grade 1 课程-1 90 2 课程-2 80 2 课程-1 100 3 课程-2 95 有以下函数依赖： Sno, Cname -&gt; Grade 3. 第三范式 (3NF)非主属性不传递函数依赖于键码。 上面的 关系-1 中存在以下传递函数依赖： Sno -&gt; Sdept -&gt; Mname 可以进行以下分解： 关系-11 Sno Sname Sdept 1 学生-1 学院-1 2 学生-2 学院-2 3 学生-3 学院-2 关系-12 Sdept Mname 学院-1 院长-1 学院-2 院长-2 八、ER 图Entity-Relationship，有三个组成部分：实体、属性、联系。 用来进行关系型数据库系统的概念设计。 实体的三种联系包含一对一，一对多，多对多三种。 如果 A 到 B 是一对多关系，那么画个带箭头的线段指向 B； 如果是一对一，画两个带箭头的线段； 如果是多对多，画两个不带箭头的线段。 下图的 Course 和 Student 是一对多的关系。 表示出现多次的关系一个实体在联系出现几次，就要用几条线连接。 下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。 联系的多向性虽然老师可以开设多门课，并且可以教授多名学生，但是对于特定的学生和课程，只有一个老师教授，这就构成了一个三元联系。 一般只使用二元联系，可以把多元联系转换为二元联系。 表示子类用一个三角形和两条线来连接类和子类，与子类有关的属性和联系都连到子类上，而与父类和子类都有关的连到父类上。 参考资料 AbrahamSilberschatz, HenryF.Korth, S.Sudarshan, 等. 数据库系统概念 [M]. 机械工业出版社, 2006. 施瓦茨. 高性能 MYSQL(第3版)[M]. 电子工业出版社, 2013. 史嘉权. 数据库系统概论[M]. 清华大学出版社有限公司, 2006. The InnoDB Storage Engine Transaction isolation levels Concurrency Control The Nightmare of Locking, Blocking and Isolation Levels! Database Normalization and Normal Forms with an Example The basics of the InnoDB undo logging and history system MySQL locking for the busy web developer 浅入浅出 MySQL 和 InnoDB Innodb 中的事务隔离级别和锁的关系","categories":[{"name":"database","slug":"database","permalink":"https://marchnineteen.github.io/categories/database/"}],"tags":[]},{"title":"java线程解析","slug":"java/javase/thread","date":"2019-03-02T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/03/02/java/javase/thread/","link":"","permalink":"https://marchnineteen.github.io/2019/03/02/java/javase/thread/","excerpt":"","text":"一些概念：并行与并发： 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力。 线程安全：经常用来描绘一段代码。指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。这个时候使用多线程，我们只需要关注系统的内存，cpu是不是够用即可。反过来，线程不安全就意味着线程的调度顺序会影响最终结果。 同步：Java中的同步指的是通过人为的控制和调度，保证共享资源的多线程访问成为线程安全，来保证结果的准确。如上面的代码简单加入@synchronized关键字。在保证结果准确的同时，提高性能，才是优秀的程序。线程安全的优先级高于性能。 volatile：多线程的内存模型：main memory（主存）、working memory（线程栈），在处理数据时，线程会把值从主存load到本地栈，完成操作后再save回去(volatile关键词的作用：每次针对该变量的操作都激发一次load and save)。针对多线程使用的变量如果不是volatile或者final修饰的，很有可能产生不可预知的结果（另一个线程修改了这个值，但是之后在某线程看到的是修改之前的值）。其实道理上讲同一实例的同一属性本身只有一个副本。但是多线程是会缓存值的，本质上，volatile就是不去缓存，直接取值。在线程安全的情况下加volatile会牺牲性能。 线程状态&amp;状态切换 对象方法： wait()：当前线程放弃对象锁，使该线程处于等待池(wait blocked pool),直到notify()/notifyAll()，线程被唤醒被放到锁定池(lock blocked pool )，释放同步锁使线程回到可运行状态（Runnable）。 notify():从对象的等待池中移走一个任意的线程并放到锁标志等待池中，只有锁标志等待池中线程能够获取锁标志；如果锁标志等待池中没有线程，则notify()不起作用。 notifyAll(): notifyAll()则从对象等待池中移走所有等待那个对象的线程并放到锁标志等待池中。 注意点：源码 wait()当前线程立即释放对象锁，notify() notifyAll() 之后 才会执行剩下代码 notify() notifyAll() 本身不会释放锁，仅仅是通知，当同步块执行完毕之后才会释放锁。 Thread线程方法： yield():正在执行的线程把运行机会交给线程池中拥有相同优先级的线程，无法保证迅速转换，运行状态转到可运行状态. join():使得一个线程在另一个线程结束后再执行。在一个线程中调用other.join(),将等待other执行完后才继续本线程。 sleep():不会释放对象锁，暂停一段时间。 interrupt()：后两个函数皆可以被打断。 使用condition控制线程通信： await(),类似wait() signal() 类似notify signalAll()类似notifyAll 高级多线程控制类：1.ThreadLocal类:2.原子类（AtomicInteger、AtomicBoolean……）12345&#x2F;&#x2F; cas方法public final boolean compareAndSet(int expect, int update) &#123;&#x2F;&#x2F;使用unsafe的native方法，实现高效的硬件级别CASreturn unsafe.compareAndSwapInt(this, valueOffset, expect, update);&#125; 3.Lock类 Condition ReentrantLock 公平锁和非公平锁不同之处在于，公平锁在获取锁的时候，不会先去检查state状态，而是直接执行aqcuire(1),即直接进入队列 so:由于公平锁需要关心队列的情况，得按照队列里的先后顺序来获取锁(会造成大量的线程上下文切换)，而非公平锁则没有这个限制。所以也就能解释非公平锁的效率会被公平锁更高。 ReentrantReadWriteLock.ReadLock ReentrantReadWriteLock.WriteLock 4.容器类 BlockingQueue ConcurrentHashMap 5.管理类 ThreadPoolExecutor 线程池构成方法参数： 1.指定核心线程数量 2. 队列排队策略： 同步移交：不会放到队列中，而是等待线程执行它。如果当前线程没有执行，很可能会新开一个线程执行。 核心线程满了，接下来进队列，队列也满了，创建新线程，直到达到最大线程数，之后再超出，会进入拒绝rejectedExecution JMX框架下的系统级管理类 ThreadMXBean","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"Java设计模式：责任链模式","slug":"java/java-design/behavioral/chainOfResponsibility","date":"2019-01-24T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/24/java/java-design/behavioral/chainOfResponsibility/","link":"","permalink":"https://marchnineteen.github.io/2019/01/24/java/java-design/behavioral/chainOfResponsibility/","excerpt":"","text":"定义(目的)使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链发送该请求，直到有一个对象处理它为止。 实现原理定义个抽象类，依赖一个本身对象，每个继承类，即可传入其它的继承类实现对象链。 代码实现： 定义处理器抽象类 依赖一个本身对象，通过构造器传入，拥有一个处理请求的抽象方法 protected Handler successor; public Handler(Handler successor) { this.successor = successor; } protected abstract void handleRequest(Request request); 请求参数类 public class Request { private RequestType type; private String name; public Request(RequestType type, String name) { this.type = type; this.name = name; } public RequestType getType() { return type; } public String getName() { return name; } } 请求类型枚举类 不同的请求类型 调用不同的处理器 public enum RequestType { TYPE1, TYPE2, TYPE3 } 定义处理器类1继承抽象类处理类型为TYPE1的请求 public class ConcreteHandler1 extends Handler { public ConcreteHandler1(Handler successor) { super(successor); } @Override protected void handleRequest(Request request) { if (RequestType.TYPE1 == request.getType()) { System.out.println(request.getName() + &quot; is handle by ConcreteHandler1&quot;); return; } if (successor != null) { successor.handleRequest(request); } } } 定义处理器类2继承抽象类处理类型为TYPE2的请求 public class ConcreteHandler2 extends Handler { public ConcreteHandler2(Handler successor) { super(successor); } @Override protected void handleRequest(Request request) { if (request.getType() == RequestType.TYPE2) { System.out.println(request.getName() + &quot; is handle by ConcreteHandler2&quot;); return; } if (successor != null) { successor.handleRequest(request); } } } 测试： public class Client { public static void main(String[] args) { Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); Request request1 = new Request(RequestType.TYPE1, &quot;request1&quot;); handler2.handleRequest(request1); Request request2 = new Request(RequestType.TYPE2, &quot;request2&quot;); handler2.handleRequest(request2); Handler handler3 = new ConcreteHandler3(handler2); Request request3 = new Request(RequestType.TYPE3, &quot;request3&quot;); handler3.handleRequest(request1); } } 输出： request1 is handle by ConcreteHandler1 request2 is handle by ConcreteHandler2 再定义一个定义处理器类3继承抽象类处理类型为TYPE3的请求 public class ConcreteHandler3 extends Handler { public ConcreteHandler3(Handler successor) { super(successor); } @Override protected void handleRequest(Request request) { if (RequestType.TYPE3 == request.getType()) { System.out.println(request.getName() + &quot; is handle by ConcreteHandler3&quot;); return; } if (successor != null) { successor.handleRequest(request); } } } 测试：使用handler3处理request1请求 public class Client { public static void main(String[] args) { Handler handler1 = new ConcreteHandler1(null); Handler handler2 = new ConcreteHandler2(handler1); Request request1 = new Request(RequestType.TYPE1, &quot;request1&quot;); Handler handler3 = new ConcreteHandler3(handler2); Request request3 = new Request(RequestType.TYPE3, &quot;request3&quot;); handler3.handleRequest(request1); } } 输出：最外层的Handler即调用所有类型的处理请求 request1 is handle by ConcreteHandler1","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：观察者模式","slug":"java/java-design/behavioral/observer","date":"2019-01-24T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/24/java/java-design/behavioral/observer/","link":"","permalink":"https://marchnineteen.github.io/2019/01/24/java/java-design/behavioral/observer/","excerpt":"","text":"定义(目的)定义对象之间的一对多依赖，当一个对象状态改变时，它的所有依赖都会收到通知并且自动更新状态。 主题（Subject）是被观察的对象，而其所有依赖者（Observer）称为观察者。 实现原理主题依赖了观察者的一个集合，观察者依赖了一个主题，生成一个观察者需要在主题进行注册，主题更新后对每个观察者进行推送 代码实现： 定义主题接口，拥有对观察者的操作方法 public interface Subject { // 注册观察者 public void registerObserver(Observer observer); // 移除观察者 public void removeObserver(Observer observer); // 提醒观察者 public void notifyObserver(); } 定义一个观察者接口，提供一个操作接口，方便主题更新时对观察者进行操作 public interface Observer { void update(float temp, float humidity, float pressure); } 定义主题接口实现类，依赖了一个观察者集合，当对主题进行更新时，循环通知各个观察者 public class WeatherSubject implements Subject { private List&lt;Observer&gt; observers; private float temperature; private float humidity; private float pressure; public WeatherSubject() { observers = new ArrayList&lt;&gt;(); } public void setMeasurements(float temperature, float humidity, float pressure) { this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; notifyObserver(); } @Override public void registerObserver(Observer observer) { observers.add(observer); } @Override public void removeObserver(Observer observer) { int i = observers.indexOf(observer); if (i &gt;= 0) { observers.remove(i); } } @Override public void notifyObserver() { for (Observer o : observers) { o.update(temperature, humidity, pressure); } } } 定义观察者实现类，每个观察者通过构造方法传入它所订阅的主题，并在主题中注册该观察者 public class StatisticsDisplay implements Observer { public StatisticsDisplay(Subject weatherData) { weatherData.registerObserver(this); } @Override public void update(float temp, float humidity, float pressure) { System.out.println(&quot;StatisticsDisplay.update: &quot; + temp + &quot; &quot; + humidity + &quot; &quot; + pressure); } } 定义另一个观察者实现类 public class CurrentConditionsDisplay implements Observer { public CurrentConditionsDisplay(Subject weatherData) { weatherData.registerObserver(this); } @Override public void update(float temp, float humidity, float pressure) { System.out.println(&quot;CurrentConditionsDisplay.update: &quot; + temp + &quot; &quot; + humidity + &quot; &quot; + pressure); } } 测试： public class Client { public static void main(String[] args) { WeatherSubject subject = new WeatherSubject(); Observer statis = new StatisticsDisplay(subject); Observer current = new CurrentConditionsDisplay(subject); subject.setMeasurements(22f, 29f, 100f); } } 输出： StatisticsDisplay.update: 22.0 29.0 100.0 CurrentConditionsDisplay.update: 22.0 29.0 100.0JDK实现第一眼看到这个模式就感觉这不就是java的监听器嘛，其实监听器就是通过这种模式实现的。 java.util.Observer java.util.EventListener javax.servlet.http.HttpSessionBindingListener","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：外观模式","slug":"java/java-design/structure/facade","date":"2019-01-24T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/24/java/java-design/structure/facade/","link":"","permalink":"https://marchnineteen.github.io/2019/01/24/java/java-design/structure/facade/","excerpt":"","text":"定义(目的)提供了一个统一的接口，用来访问子系统中的一群接口，从而让子系统更容易使用。 实现原理定义一个外观对象，在内部进行功能的封装，功能具体是在都在外观类的内部，其它方法要使用该功能调用外观对象的方法即可。 代码实现： 定义一个电影播放系统，方法代表需要功能所需步骤 public class SubSystem { public void turnOnTV() { System.out.println(&quot;turnOnTV()&quot;); } public void setCD(String cd) { System.out.println(&quot;setCD( &quot; + cd + &quot; )&quot;); } public void starWatching() { System.out.println(&quot;starWatching()&quot;); } } 定义一个外观类，封装了看电影的三步骤，客户端只需调用外观类的方法即可实现功能 public class Facade { private SubSystem subSystem = new SubSystem(); public void watchMovie(String name) { subSystem.turnOnTV(); subSystem.setCD(name); subSystem.starWatching(); } } 测试： public class Client { public static void main(String[] args) { Facade facade = new Facade(); facade.watchMovie(&quot;家有喜事&quot;); } } 测试： turnOnTV() setCD( 家有喜事 ) starWatching()","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：策略模式","slug":"java/java-design/behavioral/strategy","date":"2019-01-24T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/24/java/java-design/behavioral/strategy/","link":"","permalink":"https://marchnineteen.github.io/2019/01/24/java/java-design/behavioral/strategy/","excerpt":"","text":"定义(目的)定义一系列算法，封装每个算法，并使它们可以互换。策略模式可以让算法独立于使用它的客户端。 实现原理把对象的功能实现定义成一个接口，对象中依赖一个功能接口，通过改变接口的实现，来达到不同的功能。 代码实现： 定义功能接口 public interface CallBehavior { // 叫，不同动物叫声不同 void call(); } 功能接口实现 public class Quack implements CallBehavior { @Override public void call() { System.out.println(&quot;鸭子叫!&quot;); } } public class Squeak implements CallBehavior { @Override public void call() { System.out.println(&quot;鸡叫k!&quot;); } } 定义对象类，并依赖功能接口，通过改变接口的具体实现达到不同的功能 public class Duck { private CallBehavior behavior; public void performQuack() { if (behavior != null) { behavior.call(); } } public void setQuackBehavior(CallBehavior behavior) { this.behavior = behavior; } } 测试： public class Client { public static void main(String[] args) { Duck duck = new Duck(); CallBehavior quack = new Quack(); duck.setQuackBehavior(quack); duck.performQuack(); CallBehavior squeak = new Squeak(); duck.setQuackBehavior(squeak); duck.performQuack(); } } 输出： 鸭子叫! 鸡叫k!JDK实现 java.util.Comparator#compare() javax.servlet.http.HttpServlet javax.servlet.Filter#doFilter()","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：享元模式","slug":"java/java-design/structure/flyweight","date":"2019-01-24T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/24/java/java-design/structure/flyweight/","link":"","permalink":"https://marchnineteen.github.io/2019/01/24/java/java-design/structure/flyweight/","excerpt":"","text":"定义(目的)利用共享的方式来支持大量细粒度的对象，这些对象一部分内部状态是相同的。 实现原理在享元接口中 定义一个方法，即为对象的外部状态，每个对象的外部状态都不同在接口的实现类中添加一个成员变量作为识别标志，在创建工厂类中添加一个Map以识别标志为key，即以对象内部相同状态为key，调用方法即可改变其它状态 代码实现： 定义组享元接口 拥有改变外部对象的方法 public interface Flyweight { /** * 外部状态，每个享元对象的外部状态不同 * * @param extrinsicState */ public void extrinsicState(String extrinsicState); } 定义一个享元接口实现类，内部状态为成员变量，提供外部状态实现 public class ConcreteFlyweight implements Flyweight { private String intrinsicState; public ConcreteFlyweight(String intrinsicState) { this.intrinsicState = intrinsicState; } @Override public void extrinsicState(String extrinsicState) { System.out.println(&quot;Object address: &quot; + System.identityHashCode(this)); System.out.println(&quot;IntrinsicState: &quot; + intrinsicState); System.out.println(&quot;ExtrinsicState: &quot; + extrinsicState); } } 定义享元对象工厂类，定义一个全局变量map存储享元对象。 public class FlyweightFactory { private HashMap&lt;String, Flyweight&gt; flyweights = new HashMap&lt;&gt;(); public Flyweight getFlyweight(String intrinsicState) { if (!flyweights.containsKey(intrinsicState)) { Flyweight flyweight = new ConcreteFlyweight(intrinsicState); flyweights.put(intrinsicState, flyweight); } return flyweights.get(intrinsicState); } } 测试 public class Client { public static void main(String[] args) { FlyweightFactory factory = new FlyweightFactory(); Flyweight flyweight1 = factory.getFlyweight(&quot;aa&quot;); Flyweight flyweight2 = factory.getFlyweight(&quot;aa&quot;); flyweight1.extrinsicState(&quot;x&quot;); flyweight2.extrinsicState(&quot;y&quot;); } } 结果 Object address: 985934102 IntrinsicState: aa ExtrinsicState: x Object address: 985934102 IntrinsicState: aa ExtrinsicState: yJDK使用：Java 利用缓存来加速大量小对象的访问时间。 java.lang.Integer#valueOf(int) java.lang.Boolean#valueOf(boolean) java.lang.Byte#valueOf(byte) java.lang.Character#valueOf(char)","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"JDK1.8 HashMap源码分析","slug":"java/javase/hashMap","date":"2019-01-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/08/java/javase/hashMap/","link":"","permalink":"https://marchnineteen.github.io/2019/01/08/java/javase/hashMap/","excerpt":"","text":"Hashmap的结构，1.7和1.8有哪些区别，史上最深入的分析jdk1.7死环jdk1.7线程不安全jdk1.8扩容核心-链表复制处理HashMap1.8源码解析：resize方法 继承关系 成员变量// Hash表结构 transient Node&lt;K,V&gt;[] table; // 保证 fail-fast机制 transient int modCount; // 下一次扩容时的阈值 (capacity * load factor). int threshold; // 负载因子，决定hash表的数据填充程度，此值越大说明hash表填充的越满，空间利用率高，但是增加了查询开销，此值若太小，hash表空间利用率不高且rehash更加频繁 final float loadFactor; // 默认初始容量,必须是2的次方 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 // 最大容量，1的30次方，因为int类型32位，去掉一位符号位，只能左移30位 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 默认负载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // jdk1.8增加 链表转红黑树的阈值 static final int TREEIFY_THRESHOLD = 8; // jdk1.8增加 红黑树转链表的阈值 static final int UNTREEIFY_THRESHOLD = 6;构造函数HashMap一共有4个构造方法，主要的工作就是完成容量和加载因子的赋值。Hash表都是采用的懒加载方式，当第一次插入数据时才会创建。 // 指定默认容量和负载因子 public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; // 找到大于等于initialCapacity的最小的2的幂 若传入6 threshold=8 this.threshold = tableSizeFor(initialCapacity); } // 使用默认负载因子 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } // 参数全部都是默认值 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } // 构造一个新的 HashMap与指定的相同的映射 Map 。 public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); }基本操作添加一个元素put(K k,V v)HashMap允许K和V都为null，添加一个键值对时使用put方法，如果之前已经存在K的键值，那么旧值将会被新值替换。 // return 前一个值与key相关联 ，或null如果没有key的映射。 （A null返回也可以指示以前关联的地图null与key。 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } //先来看看hash方法，采用了Object的hash算法返回的是对象的内存地址,每个对象在内存中地址不一样，所以他们的hash值也不一样，不同的算法hashCode不同。 // 这里使用右移操作是为了让高位也参与运算提高散射率。低16位与高16位异或作为key的最终hash值。 // （h &gt;&gt;&gt; 16，表示无符号右移16位，高位补0，任何数跟0异或都是其本身，因此key的hash值高16位不变。） // 为什么要这么干呢？ 这个与HashMap中table下标的计算有关。n = table.length; index = （n-1） &amp; hash;因为，table的长度都是2的幂，因此index仅与hash值的低n位有关，hash值的高位都被与操作置为0了。 // key为null 默认为0即数组第一个 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } /** * @param hash key的Hash值 经过高位与地位的异或运算 * @param key * @param value * @param onlyIfAbsent 如果是，则不要更改现有值 * @param evict 如果为false，则表处于创建模式。 * @return 返回旧值或者null值。 */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果哈希表的长度为空 调用resize()扩容方法 n为表长度 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果当前数组下标为null值， (i = (n - 1) &amp; hash]即计算数组下标)，数组当前下标新建一个节点，即为头结点 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 数组上该位置有值,桶处有节点，发生hash冲突 else { Node&lt;K,V&gt; e; K k; // 如果头结点的值与添加的值一致，hash冲突后，key的值也一致，进行替换。将e指向p if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果与头节点不同，并且该桶目前已经是红黑树状态，调用putTreeVal()方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 如果与头节点不同,桶中仍是链表阶段 else { // 循环遍历链表 for (int binCount = 0; ; ++binCount) { // 讲e指向下一个节点，如果是null，说明该桶中只有头节点，直接添加到链表尾部即可 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果此时链表个数达到了8，那么需要将该桶处链表转换成红黑树，treeifyBin()方法将hash处的桶转成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } //如果与已有节点相同，跳出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 存在重复key进行覆盖 if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; // 子类实现 linkHashMap afterNodeAccess(e); return oldValue; } } //是一个全新节点，那么size需要+1 ++modCount; // 如果大小朝阳了阈值，需要扩容 if (++size &gt; threshold) resize(); //子类实现 afterNodeInsertion(evict); return null; }putVal()方法的流程： 1.若hash表为空，调用resize方法创建。 2.若桶的头结点为空，创建新结点放在数组中作为链表的头结点。 3.若头节点不为空，即发生hash冲突，取出头结点与当前值判断，若重复直接覆盖； 4.若不重复且当前处于红黑树状态，调用putTreeVal()方法；若不重复且当前处于链表阶段，遍历链表直到找到重复节点或者链表尾部，把该节点插入尾部；存在重复key就跳出循环。 5.存在重复key，进行value替换。 6.扩容验证。 resize()方法resize()在哈希表为null时将会初始化，但是在已经初始化后就会进行容量扩展 final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length;// 旧表容量 int oldThr = threshold;// 旧表的扩容阈值 int newCap, newThr = 0; // 旧表存在 if (oldCap &gt; 0) { // 容量已达上限 if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 否则新容量与新阈值都扩大2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } / /如果就阈值&gt;0，说明构造方法中指定了容量 else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // 初始化时没有指定阈值和容量，使用默认的容量16和阈值16*0.75=12 else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } //如果新的阈值为 0 ，就得用 新容量*加载因子 重计算一次 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; //常见扩容后的hash表 @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 属于扩容 if (oldTab != null) { //遍历旧表 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; // 当前位置有值 if ((e = oldTab[j]) != null) { oldTab[j] = null; //如果只有一个节点，直接在新表中赋值 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //如果旧哈希表中这个位置的桶是树形结构，就要把新哈希表里当前桶也变成树形结构 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order 保留旧哈希表桶中链表的顺序 // 通过e.hash &amp; oldCap将链表分为两队，参考知乎上的一段解释 /** * 把链表上的键值对按hash值分成lo和hi两串，lo串的新索引位置与原先相同[原先位j]，hi串的新索引位置为[原先位置j+oldCap]； * 链表的键值对加入lo还是hi串取决于 判断条件if ((e.hash &amp; oldCap) == 0)，因为* capacity是2的幂，所以oldCap为10...0的二进制形式，若判断条件为真，意味着 * oldCap为1的那位对应的hash位为0，对新索引的计算没有影响（新索引 * =hash&amp;(newCap-*1)，newCap=oldCap&lt;&lt;2）；若判断条件为假，则 oldCap为1的那位* 对应的hash位为1， * 即新索引=hash&amp;( newCap-1 )= hash&amp;( (oldCap&lt;&lt;2) - 1)，相当于多了10...0， * 即 oldCap * 例子： * 旧容量=16，二进制10000；新容量=32，二进制100000 * 旧索引的计算： * hash = xxxx xxxx xxxy xxxx * 旧容量-1 1111 * &amp;运算 xxxx * 新索引的计算： * hash = xxxx xxxx xxxy xxxx * 新容量-1 1 1111 * &amp;运算 y xxxx * 新索引 = 旧索引 + y0000，若判断条件为真，则y=0(lo串索引不变)，否则y=1(hi串 * 索引=旧索引+旧容量10000) */ Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; // 双链表 尾插法 if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; }resize()首先获取新容量以及新阈值，然后根据新容量创建新表。如果是扩容操作，则需要进行rehash操作，通过e.hash&amp;oldCap将链表分为两列，更好地均匀分布在新表中。 get(K k)操作get(K k)根据键得到值，如果值不存在，那么返回null public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // hash表不为空且第一个节点存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 第一个节点即为要查询的节点 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 链表不止一个头节点 if ((e = first.next) != null) { // 首节点是红黑树节点，调用getTreeNode方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 首节点是链表,循环遍历链表 do { // 匹配就返回 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } getNode()过程： 1.如果hash表为空或者长度为0或找不到hash值对应的数组位置，返回null 2.如果头节点匹配，返回头结点。 3.如果头结点不匹配且没有后续节点，返回null 4.如果头结点不匹配且头结点是红黑树类型，调用getTreeNode方法寻找节点 5.如果头结点不匹配且头结点是链表结构，从前往后遍历，找到相应的节点就返回 remove()操作remove(K k)用于根据键值删除键值对，如果哈希表中存在该键，那么返回键对应的值，否则返回null。 public V remove(Object key) { Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; // 当前hash表存在且长度大于0且数组中存在头结点 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) { Node&lt;K,V&gt; node = null, e; K k; V v; // 头节点即为key所对应的节点，node即为头节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; // 头结点有下一个节点 else if ((e = p.next) != null) { // 首节点是红黑树节点，调用getTreeNode方法 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else { // 首节点是链表,遍历链表 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } //如果存在待删除节点节点 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) { //如果节点是TreeNode，使用红黑树的方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //如果待删除节点是头节点，更改桶中的头节点即可 else if (node == p) tab[index] = node.next; //在链表遍历过程中，p代表node节点的前驱节点 else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 总体来说，removeNode（）先查出待删除的节点，查找过程与查询过程类型，只不过多了在遍历链表时还需要保存前驱节点，因为后面删除时要用到（单链表结构）。存在待删除节点，接下来再执行删除操作. 1.如果待删除节点是TreeNode，那么调用removeTreeNode()方法 2.如果待删除节点是Node，并且待删除节点就是头节点，那么将头节点更改为原有节点的下一个节点就可以了 3.如果待删除节点是Node且待删除节点不是头节点，那么将遍历过程中保存的前驱节点p的后继节点设为node的后继节点就可以了","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"Java设计模式：适配器","slug":"java/java-design/structure/adapter","date":"2019-01-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/08/java/java-design/structure/adapter/","link":"","permalink":"https://marchnineteen.github.io/2019/01/08/java/java-design/structure/adapter/","excerpt":"","text":"定义(目的)适配器就是一种适配中间件，它存在于不匹配的二者之间，用于连接二者，将不匹配变得匹配，简单点理解就是平常所见的转接头，转换器之类的存在。 把一个类接口转换成另一个用户需要的接口。 实现原理 通过组合的方式。 通过继承来实现适配器功能。 代码实现： 定义一个鸭接口 方法为鸭子叫 public interface Duck { void quack(); 定义一个火鸡接口 方法为鸡叫 public interface Turkey { void gobble(); 鸭子实现类 public class WildDuck implements Duck { @Override public void quack() { System.out.println(&quot;鸭子叫&quot;); } } 火鸡实现类 public class WildTurkey implements Turkey { @Override public void gobble() { System.out.println(&quot;火鸡叫&quot;); } } 现在鸭子只能发出鸭子叫，鸡只能发出鸡叫，我们想要鸭子发出鸡的叫声。添加鸭子适配器。 public class DuckAdapter implements Turkey { Duck duck; public DuckAdapter(Duck duck) { this.duck = duck; } @Override public void gobble() { duck.quack(); } } 组合方式，适配器构造器需要一个鸭子对象，适配器实现了火鸡的接口，通过调用鸭子对象的方法，实现了鸭子发生了鸡叫。 public class DuckAdapter extends Turkey WildTurkey implements Turkey { @Override public void gobble() { gobble.quack(); } } 继承方式，适配器构造器需要一个鸭子对象，适配器实现了火鸡的接口，通过调用鸭子对象的方法，实现了鸭子发生了鸡叫。","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：桥接器","slug":"java/java-design/structure/bridge","date":"2019-01-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/08/java/java-design/structure/bridge/","link":"","permalink":"https://marchnineteen.github.io/2019/01/08/java/java-design/structure/bridge/","excerpt":"","text":"定义(目的)将抽象与实现分离开来，使它们可以独立变化。 抽象与实现解耦，例如一个生产线的机器，将参数设定与具体生产的过程实现分离开，使整个生产线更加灵活，用一套参数也可以使用不同的工作模式。 其中参数设定与生产过程属于两种不同的维度，桥接模式所做的事情就是将不同的维度联结在一起！ 实现原理 在一个类中通过组合另一个对象，调用时只需在当前类调用对象方法即可，实现解耦。 代码实现： 定义电视机抽象类,拥有3个方法。 public abstract class Tv { public abstract void on(); public abstract void off(); public abstract void tuneTunnel(); 定义一个电视机的实现类，Sony电视机。 public class SonyTv extends Tv { @Override public void on() { System.out.println(&quot;SonyTv,on&quot;); } @Override public void off() { System.out.println(&quot;SonyTv,off&quot;); } @Override public void tuneTunnel() { System.out.println(&quot;SonyTv,tuneTunnel&quot;); } 定义一个遥控器抽象类。组合了一个电视机对象。 protected Tv tv; public RemoteControl(Tv tv) { this.tv = tv; } public abstract void on(); public abstract void off(); public abstract void tuneTunnel(); 定义一个遥控器的实现类，Sony电视机遥控器。 public class SonyRemoteControl extends RemoteControl { public SonyRemoteControl(Tv tv) { super(tv); } @Override public void on() { System.out.println(&quot;sonyRemoteControl,on&quot;); tv.on(); } @Override public void off() { System.out.println(&quot;sonyRemoteControl,off&quot;); tv.off(); } @Override public void tuneTunnel() { System.out.println(&quot;sonyRemoteControl,tuneTunnel&quot;); tv.off(); } } 在生成sony电视机遥控器时，传入一个sony电视机对象，即可使用该遥控器实现该电视机的状态变换。 public class Client { public static void main(String[] args) { Tv sonyTv = new SonyTv(); SonyRemoteControl sonyRemoteControl = new SonyRemoteControl(sonyTv); sonyRemoteControl.on(); sonyRemoteControl.off(); sonyRemoteControl.tuneTunnel(); } }","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：装饰者","slug":"java/java-design/structure/decorator","date":"2019-01-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/08/java/java-design/structure/decorator/","link":"","permalink":"https://marchnineteen.github.io/2019/01/08/java/java-design/structure/decorator/","excerpt":"","text":"定义(目的)为对象动态添加功能。组合模式是部分和整理的关系，而装饰器模式只是额外增加某些功能。 实现原理装饰者（Decorator）和具体组件（ConcreteComponent）都继承自组件（Component）,装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。 就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。 装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 代码实现：设计不同种类的饮料，饮料可以添加配料，比如可以添加牛奶，并且支持动态添加新配料。每增加一种配料，该饮料的价格就会增加，要求计算一种饮料的价格。 下面实现在 DarkRoast 饮料上新增新添加 Mocha 配料，之后又添加了 Milk 配料。DarkRoast 被 Mocha 包裹，Mocha 又被 Milk 包裹。它们都继承自相同父类，都有 cost() 方法，外层类的 cost() 方法调用了内层类的 cost() 方法。 定义一个组件（Component）接口,这里为饮料。装饰者和具体组件都要实现它。 public interface Beverage { public double cost(); } 具体组件实现DarkRoast饮料 public class DarkRoast implements Beverage { @Override public double cost() { return 1; } } 定义一个装饰者抽象类，实现了饮料接口，拥有饮料的方法，并关联了饮料接口对象。 public abstract class CondimentDecorator implements Beverage { protected Beverage beverage; public CondimentDecorator(Beverage beverage) { this.beverage = beverage; } } 装饰者实现类Milk，继承了装饰者类 public class Milk extends CondimentDecorator { public Milk(Beverage beverage) { super(beverage); } @Override public double cost() { return 1 + beverage.cost(); } } 装饰者实现类Mocha，继承了装饰者类 public class Mocha extends CondimentDecorator { public Mocha(Beverage beverage) { super(beverage); } @Override public double cost() { return 1 + beverage.cost(); } } 测试：当执行cost()方法时会一层一层从内往外调用。 public class Client { public static void main(String[] args) { Beverage beverage = new DarkRoast();// 一杯饮料 beverage = new Mocha(beverage);// 饮料里加mocha beverage = new Milk(beverage);// 饮料里加牛奶 System.out.println(beverage.cost());//总价 } }","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"Java设计模式：组合模式","slug":"java/java-design/structure/composite","date":"2019-01-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/08/java/java-design/structure/composite/","link":"","permalink":"https://marchnineteen.github.io/2019/01/08/java/java-design/structure/composite/","excerpt":"","text":"定义(目的)将对象组合成树形结构来表示“整体/部分”层次关系，允许用户以相同的方式处理单独对象和组合对象。 实现原理组件（Component）类是组合类（Composite）和叶子类（Leaf）的父类，可以把组合类看成是树的中间节点。组合对象拥有一个或多个组件对象，因此组合对象的操作可以委托给组件对象去处理，而组件对象可以是另一个组合对象或者叶子对象。 代码实现： 定义组件抽象类 public abstract class Component { protected String name; public Component(String name) { this.name = name; } public void print() { print(0); } public abstract void print(int level); public abstract void add(Component component); public abstract void remove(Component component); } 定义一个组合类，继承组件类，并依赖了组件类，依赖的组件类可以是另一个组合对象或者叶子对象 public class Composite extends Component { private List&lt;Component&gt; child; public Composite(String name) { super(name); child = new ArrayList&lt;&gt;(); } @Override public void print(int level) { for (int i = 0; i &lt; level; i++) { System.out.print(&quot;--&quot;); } System.out.println(&quot;Composite:&quot; + name); for (Component component : child) { component.print(level + 1); } } @Override public void add(Component component) { child.add(component); } @Override public void remove(Component component) { child.remove(component); } } 定义一个叶子类，继承组件类。 public class Leaf extends Component{ public Leaf(String name) { super(name); } @Override public void print(int level) { for (int i = 0; i &lt; level; i++) { System.out.print(&quot;--&quot;); } System.out.println(&quot;left:&quot; + name); } @Override public void add(Component component) { throw new UnsupportedOperationException(); // 牺牲透明性换取单一职责原则，这样就不用考虑是叶子节点还是组合节点 } @Override public void remove(Component component) { throw new UnsupportedOperationException(); } 测试 public class Client { public static void main(String[] args) { Composite root = new Composite(&quot;root&quot;); Component node1 = new Leaf(&quot;1&quot;); Component node2 = new Composite(&quot;2&quot;); Component node3 = new Leaf(&quot;3&quot;); root.add(node1); root.add(node2); root.add(node3); Component node21 = new Leaf(&quot;21&quot;); Component node22 = new Composite(&quot;22&quot;); node2.add(node21); node2.add(node22); Component node221 = new Leaf(&quot;221&quot;); node22.add(node221); root.print(); } } 结果 Composite:root --left:1 --Composite:2 ----left:21 ----Composite:22 ------left:221 --left:3","categories":[{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"}],"tags":[]},{"title":"数据结构概念","slug":"datastructure/index","date":"2019-01-04T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2019/01/04/datastructure/index/","link":"","permalink":"https://marchnineteen.github.io/2019/01/04/datastructure/index/","excerpt":"","text":"数据结构算法学习（一）：数据结构与算法概念解析什么是数据结构数据（data）：符号集合，处理对象。 数据元素（data element），由数据项（data item） 组成。 关键字（key）识别元素，主关键字（primary key） 唯一识别元素。 数据结构（data structure）指数据元素之间存在的关系。包含以下三方面： 数据的逻辑结构 数据的存储结构 数据操作 数据的逻辑结构线性结构：数据元素只有一个前驱数据元素和一个后继数据元素。结构中的数据元素之间存在一对一的关系。 非线性结构： 1.树结构：每个数据元素只有一个前驱数据元素，可有零个或若干个后继数据元素。结构中的数据元素之间存在一对多的关系。 2.图结构：每个数据元素可有零个或若干个前驱数据元素，零个或若干个后继数据元素。结构中的数据元素之间存在多对多的关系。 数据的存储结构顺序存储结构:用数据元素在存储器中的相对位置来表示数据元素之间的逻辑关系。 链式存储结构：在每一个数据元素中增加一个存放地址的指针，用此指针来表示数据元素之间的逻辑关系。 数据操作1.初始化。2.判断是否空状态。3.存取，指获得、设置指定元素值。4.统计数据元素个数。5.遍历（traverse），指按照某种次序访问一个数据结构中的所有元素，并且每个数据元素只被访问一次。遍历一种数据结构，将得到一个所有数据元素的线性序列。6.插入（insert）、删除（remove）指定元素。7.查找（search），指在数据结构中寻找满足给定条件的数据元素。8.排序（sort），指对数据元素按照指定关键字值的大小递增（或递减）次序重新排列。 什么是算法一个算法（Algorithm）是一个有穷规则的集合，其规则确定一个解决某一特定类型问题的操作序列。 算法定义：有穷性，确定性，输入，输出，可行性 算法设计目标：正确性，可读性，健壮性，高时间效率，高空间效率 时间复杂度算法的时间效率指算法的执行时间随问题规模的增长而增长的趋势，通常采用时间复杂度来度量算法的时间效率。T(n)=O(f(n)) 一个算法花费的时间与算法中语句的执行次数成正比例，哪个算法中语句执行次数多，它花费时间就多。一个算法中的语句执行次数称为语句频度或时间频度。记为T(n) 一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n),使得当n趋近于无穷大时，T(n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数。记作T(n)=O(f(n)),称O(f(n)) 为算法的渐进时间复杂度，简称时间复杂度。 常见的算法的时间 复杂度之间的关系为： O(1)&lt;O(logn)&lt;O(n)&lt;O(nlog n)&lt;O(n2)&lt;O(2n)&lt;O(n!)&lt;O(n的n次幂) 1.一条简单语句的时间复杂度是O(1)。 int count=0; 2.一个循环的时间复杂度是O(n)。 int n=8, count=0; for (int i=1; i&lt;=n; i++) count++; //循环体执行n次 3.以下循环语句的时间复杂度是O(log2 n)。 for (int i=1; i&lt;=n; i*=2) //i按2的幂（1,2,4,8）递增 count++; //循环体执行1+ 次 4.以下二重循环的时间复杂度为O(n2)。 for (int i=1; i&lt;=n; i++) for (int j=1; j&lt;=n; j++) 5.以下二重循环的时间复杂度是O(n×log2n)。 for (int i=1; i&lt;=n; i*=2) //循环log2n次 for (int j=1; j&lt;=n; j++) //循环n次 6.以下二重循环的时间复杂度是O(n)。 for (int i=1; i&lt;=n; i*=2) //循环log2n次 for (int j=1; j&lt;=i; j++) //循环i次 //循环次数 空间复杂度算法所需存储空间的度量，记作： S(n)=O( f(n) ) 其中 n 为问题的规模。 一个算法在计算机存储器上所占用的存储空间，包括存储算法本身所占用的存储空间，算法的输入输出数据所占用的存储空间和算法在运行过程中临时占用的存储空间这三个方面。如果额外空间相对于输入数据量来说是个常数，则称此算法是原地工作。 算法的输入输出数据所占用的存储空间是由要解决的问题决定的，是通过参数表由调用函数传递而来的，它不随本算法的不同而改变。存储算法本身所占用的存储空间与算法书写的长短成正比，要压缩这方面的存储空间，就必须编写出较短的算法。","categories":[{"name":"datastructure","slug":"datastructure","permalink":"https://marchnineteen.github.io/categories/datastructure/"}],"tags":[]},{"title":"文件查找之which&whereis&locate","slug":"linux-command/which&whereis&locate","date":"2018-12-04T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/12/04/linux-command/which&whereis&locate/","link":"","permalink":"https://marchnineteen.github.io/2018/12/04/linux-command/which&whereis&locate/","excerpt":"","text":"whichwhich命令格式：which 可执行文件名称 命令功能：在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 命令参数-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 -p 与-n参数相同，但此处的包括了文件的路径。 -w 指定输出时栏位的宽度。 -V 显示版本信息whereiswhereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 whereis命令格式：whereis [-bmsu] [BMS 目录名 -f ] 文件名 命令功能：whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件，或是帮助文件。whereis 程序还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力 命令参数-b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。locatelocate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 locate命令格式：whereis [-bmsu] [BMS 目录名 -f ] 文件名 命令功能：locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的，locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab) locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录，可以使用特殊字元（如”” 或”?”等）来指定范本样式，如指定范本为kcpaner, locate会找出所有起始字串为kcpa且结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。 locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库，在 执行loacte时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立即修改索引数据库。 命令参数-e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d 指定资料库的路径 -h 显示辅助讯息 -V 显示程式的版本讯息","categories":[{"name":"linux-command","slug":"linux-command","permalink":"https://marchnineteen.github.io/categories/linux-command/"}],"tags":[]},{"title":"nginx基础配置","slug":"nginx/nginxBase","date":"2018-12-03T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/12/03/nginx/nginxBase/","link":"","permalink":"https://marchnineteen.github.io/2018/12/03/nginx/nginxBase/","excerpt":"","text":"#全局块 start #配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 ########### 每个指令必须有分号结束。################# #user nobody; #配置用户或者组，默认为nobody nobody。 worker_processes 1;#允许生成的进程数，默认为1 #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emerg #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid;#指定nginx进程运行文件存放地址 #全局块 end #events块 start #配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等 events { accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off #use epoll; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 1024; #最大连接数，默认为1024 } #events块 end #http块 start #可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 http { include mime.types;#文件扩展名与文件类型映射表 default_type application/octet-stream;#默认文件类型 #access_log off; #取消服务日志 #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; #自定义格式 # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 #sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 #tcp_nopush on; #开启或者关闭nginx在FreeBSD上使用TCP_NOPUSH套接字选项， 在Linux上使用TCP_CORK套接字选项。 选项仅在使用sendfile的时候才开启。 #开启此选项允许在Linux和FreeBSD4.*上将响应头和正文的开始部分一起发送；一次性发送整个文件 #keepalive_timeout 0; #连接超时时间，默认为65s，可以在http，server，location块。 keepalive_timeout 65; #gzip on;是否开启Gzip 压缩 #gzip_min_length 1k; 不压缩临界值，大于1K的才压缩，一般不用改 #gzip_buffers 4 16k; #gzip_http_version 1.0; 用了反向代理的话，末端通信是HTTP/1.0，默认是HTTP/1.1 #gzip_comp_level 2; 压缩级别，1-10，数字越大压缩的越好，时间也越长 #gzip_types text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; #进行压缩的文件类型，缺啥补啥就行了，JavaScript有两种写法，最好都写上吧，总有人抱怨js文件没有压缩，其实多写一种格式就行了 #gzip_vary off; 跟Squid等缓存服务有关，on的话会在Header里增加&quot;Vary: Accept-Encoding&quot; #gzip_disable &quot;MSIE [1-6]\\.&quot;; IE6对Gzip不怎么友好，不给它Gzip了 #server块 start #配置虚拟主机的相关参数，一个http中可以有多个server。 server { listen 8080; #监听端口 server_name localhost; #监听地址 #charset koi8-r; #access_log logs/host.access.log main; #location块 start #配置请求的路由，以及各种页面的处理情况。 location / { root html; #根目录 index index.html index.htm; #设置默认页 } #location块 end #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\\.ht { # deny all; #} } #server块 end # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} } #http块 end","categories":[{"name":"nginx","slug":"nginx","permalink":"https://marchnineteen.github.io/categories/nginx/"}],"tags":[]},{"title":"chmod指令学习","slug":"linux-command/chmod","date":"2018-11-29T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/11/29/linux-command/chmod/","link":"","permalink":"https://marchnineteen.github.io/2018/11/29/linux-command/chmod/","excerpt":"","text":"命令格式：chmod [-cfvR] [–help] [–version] mode file 命令功能：用于改变文件或目录的访问权限，用它控制文件或目录的访问权限。 命令参数必要参数：-c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息选择参数：--reference=&lt;目录或者文件&gt; 设置成具有指定目录或者文件具有相同的权限 --version 显示版本信息 &lt;权限范围&gt;+&lt;权限设置&gt; 使权限范围内的目录或者文件具有指定的权限 &lt;权限范围&gt;-&lt;权限设置&gt; 删除权限范围的目录或者文件的指定权限 &lt;权限范围&gt;=&lt;权限设置&gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围：u ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组权限代号：r ：读权限，用数字4表示 w ：写权限，用数字2表示 x ：执行权限，用数字1表示 - ：删除权限，用数字0表示 s ：特殊权限 文字设定法:chmod ［who］ ［+ | - | =］ ［mode］ 文件名 例子： chmod u+r 给拥有者添加可读权限 数字设定法: 0表示没有权限，1表示可执行权限，2表示可写权限，4表示可读权限，然后将其相加。所以数字属性的格式应为3个从0到7的八进制数，其顺序是（u）（g）（o） chmod ［mode］ 文件名 chmod 751 file 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限","categories":[{"name":"linux-command","slug":"linux-command","permalink":"https://marchnineteen.github.io/categories/linux-command/"}],"tags":[]},{"title":"chown指令学习","slug":"linux-command/chown","date":"2018-11-29T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/11/29/linux-command/chown/","link":"","permalink":"https://marchnineteen.github.io/2018/11/29/linux-command/chown/","excerpt":"","text":"命令格式：chown [选项]… [所有者][:[组]] 文件… 命令功能：通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。 命令参数必要参数：-c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身选择参数：--reference=&lt;目录或文件&gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 --from=&lt;当前用户：当前群组&gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 --help 显示帮助信息 --version 显示版本信息","categories":[{"name":"linux-command","slug":"linux-command","permalink":"https://marchnineteen.github.io/categories/linux-command/"}],"tags":[]},{"title":"jvm学习（一）","slug":"java/jvm/jvm(1)","date":"2018-10-31T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/10/31/java/jvm/jvm(1)/","link":"","permalink":"https://marchnineteen.github.io/2018/10/31/java/jvm/jvm(1)/","excerpt":"","text":"一：内存区域 线程私有(针对于方法)： 程序计数器（Program Count Register）：如果线程正在执行java方法，计数器记录正在执行的虚拟机字节码地址；Native方法，值为空。 虚拟机栈（Vm Stack）: 描述Java方法执行的内存模型：每个方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等。 人们常说的Java内存分为堆内存（Heap）和栈内存（Stack），这个栈就是虚拟机栈，或者说是机栈中局部变量表部分。 局部变量表（虚拟机栈）存放编译器可知的基本数据类型和对象引用。 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常；栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 本地方法栈（Native Method Stack）：作用与虚拟机栈相似，本地方法栈执行Native方法。 线程共享（针对于Class）： 堆（Heap）：存放所有对象实例以及数组，是垃圾回收的主要区域。 现在垃圾收集器基本采用分代收集算法，主要思想为针对不用类型的对象采取不同的垃圾回收算法，可将堆分为新生代和老年代，还可细分。 从内存分配的角度，堆可能分出多个线程私有的分配缓冲区(TLAB)，只是为了更好回收内存，更快分配内存，存储对象不变。 堆无需连续内存，可以动态增加，增加失败会抛出OutOfMemoryError 异常。可以通过 -Xms 和 -Xmx 两个虚拟机参数来指定一个程序的堆内存大小，第一个参数设置初始值，第二个参数设置最大值。java -Xms1M -Xmx2M。 方法区（Method Area）：用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 和堆一样不需要连续的内存，还可以选择不实现垃圾回收，对这一区域内存回收目标主要是针对常量池和类型的卸载，一般难以实现，效果较差。 HotSpot 虚拟机把它当成永久代来进行垃圾回收。但是很难确定永久代的大小，因为它受到很多因素影响，并且每次 Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。 运行时常量池（Runtime Constant Pool）：是方法区的一部分。Class 文件中的常量池（编译器生成的各种字面量和符号引用）会在类加载后被放入这个区域。 具备动态性，除了再编译器生成的常量放入这一区域外，还允许动态生成。常量不仅仅再编译期间才能产生，在运行时也可能产生新的常量，例如String类的intern()。 受到方法区内存大小限制，无法申请到内存时会抛出OutOfMemoryError异常。 直接内存：不是虚拟机运行时数据区的一部分。jdk1.4中引入NIO，可以直接使用native函数库分配堆外的内存，然后通过一个存储在Java堆里的DirectByteBuffer对象作为这块内存的引用进行操作，避免了Java堆和Native对中来回复制数据显著提高性能。 二：HotSpot虚拟机对象对象的创建 空间划分（内存分配）：堆采用的垃圾收集器是否带有压缩整理功能–&gt;堆是否规整–&gt;内存的分配方式，规整采用指针碰撞方法，否则采用空闲列表方式 对象在创建中是否频繁（并发问题）： 同步处理，CAS加失败重试保证原子性 本地线程分配缓冲区（TLAB）：每个线程在Java堆中预先分配一小块内存。线程私有内存。 内存分配完成后，进行对象实例字段的初始化（不包括对象头，内存空间都为零值）；若使用TLAB，则可提前在TLAB中分配。 对象头设置：存放类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。虚拟机当前运行状态（如是否启用偏向锁）不同，对象头有不同的设置方式。 上述工作完成后，虚拟机角度新的对象已经产生，程序角度对象创建刚刚开始–方法还未执行。 对象的内存布局 对象的访问定位 Java程序通过栈上的reference（指向对象的引用）数据操作堆上的具体数据。访问方式由虚拟机实现。主流方式有2种。 句柄：堆中划分句柄池，reference存储对象的句柄地址，句柄包含对象实例数据与类型数据（类数据）各自的具体地址。优点：在对象被移动时（垃圾收集时移动对象是非常普遍的行为）只会改变句柄中的实例数据指针，reference本事不需要修改。 直接指针：reference存储的直接是对象的地址，对象的实例数据中要放置访问类型数据的指针。优点：速度快，节省了一次指针定位的时间开销。 三：垃圾收集 垃圾收集需要考虑三个问题：回收哪些内存，什么时候回收，怎么回收 垃圾收集器主要针对堆和方法区进行。 程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后也会消失，因此不需要对这三个区域进行垃圾回收。 判断一个对象是否可被回收（回收哪些内存）1.引用计数算法 给对象添加一个引用计数器，当对象增加引用时就加一，失效一个引用时就减一。引用计数器为0的对象表示可以回收。 由于存在循环引用，引用计数器永远不为0，导致永远不会被回收。 2.可达性分析算法通过 Roots作为起点，能够到达的对象被视为存活，不可达的对象可以回收。 可作为GC Roots的对象：（全局性引用如常量和类静态变量，应用上下文如帧栈中的本地变量表） 虚拟机栈（帧栈中的本地变量两）中引用的对象 方法区中的类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中的JNI（即一般说的Native方法）引用的对象。 3.对象生存还是死亡（finalize()方法）在可达性分析算法过程中不可达的对象并非一定会被回收。在可达性分析算法被认为无引用链后，需要2步才能真正宣告对象已死。 进行一次筛选，筛选条件为对象是否有必要执行finalize()方法，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。 若未覆盖finalize方法，则直接将其回收。 自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会调用 finalize() 方法。 4.方法区回收因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，因此在方法区上进行回收性价比不高。主要是对常量池的回收和对类的卸载。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。 类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 可以通过 -Xnoclassgc 参数来控制是否对类进行卸载。 引用类型 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。 Java 提供了四种强度不同的引用类型。 1.强引用 被强引用关联的对象不会被回收。使用 new 一个新对象的方式来创建强引用。 Object obj = new Object();2.软引用 被软引用关联的对象只有在内存不够的情况下才会被回收。使用 SoftReference 类来创建软引用。 Object obj = new Object(); SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj); obj = null; // 使对象只被软引用关联3.弱引用 被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。使用 WeakReference 类来实现弱引用。 Object obj = new Object(); SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj); obj = null; // 使对象只被软引用关联4.虚引用 又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。 为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。 使用 PhantomReference 来创建虚引用。 Object obj = new Object(); PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, null); obj = null;垃圾收集算法（怎么回收）1.标记 - 清除 标记要回收的对象，然后清除。 不足： 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2.标记 - 整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 3.复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将新生代划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。 HotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 4.分代收集 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 垃圾收集器HotSpot垃圾收集器 连线表示可以配合使用。 单线程与多线程：单线程指的是垃圾收集器只使用一个线程进行收集，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 1.Serial 收集器串行，单线程。优点：高效，单cpu环境没有线程交互的切换，拥有最高的单线程收集效率。 client模式的下的默认新生代垃圾收集器。因为在该应用场景下，分配给虚拟机管理的内存一般来说不会很大。 Serial 收集器收集几十兆甚至一两百兆的新生代停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿是可以接受的。 2.ParNew 收集器 Serial 收集器的多线程版本。 是 Server 模式下的虚拟机首选新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合工作。 默认开启的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数。 3.Parallel Scavenge 收集器 多线程收集器。 其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。 缩短停顿时间是以牺牲吞吐量和新生代空间来换取的：新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。 可以通过一个开关参数打开 GC 自适应的调节策略（GC Ergonomics），就不需要手工指定新生代的大小（-Xmn）、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 4.Serial Old 收集器 是 Serial 收集器的老年代版本，也是给 Client 模式下的虚拟机使用。如果用在 Server 模式下，它有两大用途： 在 JDK 1.5 以及之前版本（Parallel Old 诞生以前）中与 Parallel Scavenge 收集器搭配使用。 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 5.Parallel Old 收集器是 Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS 收集器CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。 分为以下四个流程： 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 具有以下缺点： 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 7. G1 收集器G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。 G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 重新标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 并发清除：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 具备如下特点： 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。Full GC。 四：内存分配与回收策略Minor GC 和 Full GC Minor GC：发生在新生代上，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：发生在老年代上，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。 内存分配策略1.对象优先在Eden分配 大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。 2.大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。 经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。 -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 区和 Survivor 区之间的大量内存复制。 3.长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。 -XX:MaxTenuringThreshold 用来定义年龄的阈值。 4.动态对象年龄判定 虚拟机并不是永远地要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 5.空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。 如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。 Full GC 的触发条件 对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件： 1.调用 System.gc() 只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。 2.老年代空间不足 老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。 为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。 3.空间分配担保失败 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。 ####4.JDK 1.7 及以前的永久代空间不足 在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。 当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。 为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。 5.Concurrent Mode Failure 执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 五：类加载机制类是在运行期间第一次使用时动态加载的，而不是编译时期一次性加载。因为如果在编译时期一次性加载，那么会占用很多的内存。 类的生命周期 类加载过程 ####加载 查找并加载类的二进制数据加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的 java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个 java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 验证：确保被加载的类的正确性验证是连接阶段的第一步，目的是保证加载的类符合当前虚拟机的要求。验证阶段大致分四步： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以 0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了 java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用 -Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备：为类的静态变量分配内存，初始化默认值 类型默认值 不是程序赋值准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意： 这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。 如果类字段的字段属性表中存在 ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。 解析：把类中的符号引用转换为直接引用解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化 初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式： 声明类变量是指定初始值 使用静态代码块为类变量指定初始值 初始化步骤： 假如这个类还没有被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句 类初始化时机（主动，被动） 只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种： 创建类的实例，也就是new的方式 反射（如 Class.forName(“com.Test”) 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 初始化某个类的子类，则其父类也会被初始化 Java虚拟机启动时被标明为启动类的类（ JavaTest），直接使用 java.exe命令来运行某个主类 被动引用的常见例子包括： 通过子类引用父类的静态字段，不会导致子类初始化。 System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 SuperClass[] sca = new SuperClass[10]; 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 System.out.println(ConstClass.HELLOWORLD); 结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载器类加载机制","categories":[{"name":"JVM","slug":"JVM","permalink":"https://marchnineteen.github.io/categories/JVM/"}],"tags":[]},{"title":"rm特殊删除","slug":"linux-command/rm","date":"2018-10-29T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/10/29/linux-command/rm/","link":"","permalink":"https://marchnineteen.github.io/2018/10/29/linux-command/rm/","excerpt":"","text":"特殊删除删除所有-p开头的文件rm – -P.* 需要用–进行特殊处理 自定义回收站功能myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv “$@” $D &amp;&amp; echo “moved to $D ok”; } alias rm=’myrm’","categories":[{"name":"linux-command","slug":"linux-command","permalink":"https://marchnineteen.github.io/categories/linux-command/"}],"tags":[]},{"title":"mysql概要","slug":"database/mysql","date":"2018-09-05T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/09/05/database/mysql/","link":"","permalink":"https://marchnineteen.github.io/2018/09/05/database/mysql/","excerpt":"","text":"提到mysql等数据库，当然绕不开它最基本的概念，数据结构，数据库的索引就是数据结构最好的应用。对数据结构没有概念的同学请点击 一：存储引擎（存储引擎提供不同的存储机制、索引技巧、锁定水平等功能）InnoDB与MYISAM比较 功 能 MYISAM InnoDB 存储限制 256TB 64TB 支持事物 不支持 支持 支持锁级别 表级锁 表级锁，行级锁 支持外键 不支持 支持 支持全文索引 支持 不支持 支持数索引 支持 支持 支持哈希索引 不支持 不支持 支持数据缓存 不支持 支持 二：索引索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 1. B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。 因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。 除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。 2. 哈希索引哈希索引能以 O(1) 时间进行查找，但是失去了有序性： 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 数据量大时，会产生hash冲突，性能降低。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 3. 全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。 查找条件使用 MATCH AGAINST，而不是普通的 WHERE。 全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。 InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。 4. 空间数据索引MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 三：数据库拆分四：数据库主从与读写分离","categories":[{"name":"database","slug":"database","permalink":"https://marchnineteen.github.io/categories/database/"}],"tags":[]},{"title":"java正则表达式例子","slug":"java/javase/regularExpression","date":"2018-08-28T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/08/28/java/javase/regularExpression/","link":"","permalink":"https://marchnineteen.github.io/2018/08/28/java/javase/regularExpression/","excerpt":"","text":"[正则表达式]文本框输入内容控制 整数或者小数：^[0-9]+.{0,1}[0-9]{0,2}$ 只能输入数字：”^[0-9]*$”。 只能输入n位的数字：”^\\d{n}$”。 只能输入至少n位的数字：”^\\d{n,}$”。 只能输入m~n位的数字：。”^\\d{m,n}$” 只能输入零和非零开头的数字：”^(0|[1-9][0-9]*)$”。 只能输入有两位小数的正实数：”^[0-9]+(.[0-9]{2})?$”。 只能输入有1~3位小数的正实数：”^[0-9]+(.[0-9]{1,3})?$”。 只能输入非零的正整数：”^+?[1-9][0-9]*$”。 只能输入非零的负整数：”^-[1-9][]0-9”*$。 只能输入长度为3的字符：”^.{3}$”。 只能输入由26个英文字母组成的字符串：”^[A-Za-z]+$”。 只能输入由26个大写英文字母组成的字符串：”^[A-Z]+$”。 只能输入由26个小写英文字母组成的字符串：”^[a-z]+$”。 只能输入由数字和26个英文字母组成的字符串：”^[A-Za-z0-9]+$”。 只能输入由数字、26个英文字母或者下划线组成的字符串：”^\\w+$”。 验证用户密码：”^[a-zA-Z]\\w{5,17}$”正确格式为：以字母开头，长度在6~18之间，只能包含字符、数字和下划线。 验证是否含有^%&amp;’,;=?$&quot;等字符：”[^%&amp;’,;=?$\\x22]+”。 只能输入汉字：”^[\\u4e00-\\u9fa5]{0,}$” 验证Email地址：”^\\w+([-+.]\\w+)@\\w+([-.]\\w+)*.\\w+([-.]\\w+)$”。 验证InternetURL：”^http://([\\w-]+.)+[\\w-]+(/[\\w-./?%&amp;=]*)?$”。 验证电话号码：”^((\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$”正确格式为：”XXX-XXXXXXX”、”XXXX-XXXXXXXX”、”XXX-XXXXXXX”、”XXX-XXXXXXXX”、”XXXXXXX”和”XXXXXXXX”。 验证身份证号（15位或18位数字）：”^\\d{15}|\\d{18}$”。 验证一年的12个月：”^(0?[1-9]|1[0-2])$”正确格式为：”01”～”09”和”1”～”12”。 验证一个月的31天：”^((0?[1-9])|((1|2)[0-9])|30|31)$”正确格式为；”01”～”09”和”1”～”31”。 匹配中文字符的正则表达式： [\\u4e00-\\u9fa5] 匹配双字节字符(包括汉字在内)：[^\\x00-\\xff] 应用：计算字符串的长度（一个双字节字符长度计2，ASCII字符计1） String.prototype.len=function(){return this.replace(/[^\\x00-\\xff]/g,”aa”).length;} 匹配空行的正则表达式：\\n[\\s| ]*\\r 匹配html标签的正则表达式：&lt;(.)&gt;(.)&lt;/(.)&gt;|&lt;(.)/&gt; 匹配首尾空格的正则表达式：(^\\s)|(\\s$)","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"java异常体系结构","slug":"java/javase/exception","date":"2018-08-08T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/08/08/java/javase/exception/","link":"","permalink":"https://marchnineteen.github.io/2018/08/08/java/javase/exception/","excerpt":"","text":"java异常体系结构图 从图中可以发现（列出要点，简要说明）： 所以异常类的父类为Throwable类（表示可抛出），直接继承为Error和Exception两个子类，Error也是异常的一种。 Error是程序无法处理的错误，它是由JVM产生和抛出的，比如OutOfMemoryError、ThreadDeath等。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。Exception是程序本身可以处理的异常，这种异常分两大类运行时异常和非运行时异常。程序中应当尽可能去处理这些异常。 RuntimeException（也称不检查异常）：即可以编译通过，一般由程序的逻辑错误引起，开发过程中应尽量避免。例如：NullPointerException，IndexOutOfBoundsException等。自定义异常一般继承此类。 RuntimeException以外的异常（IOException）：编译器在编译阶段进行处理，程序必须处理此类异常否则无法通过编译。 try-catch-finally-return具体例子见(个人demo): https://github.com/MarchNineteen/spring-example/blob/master/spring-example-test/src/main/java/com/wyb/test/java/exception/ReturnFinallyTest.java 自定义全局异常处理（配套源码） https://github.com/MarchNineteen/spring-example/tree/master/spring-example-exception 常见的异常打印信息 getMessage(): 返回此throwable的详细消息字符串，只会获得具体的异常名称，比如说NullPoint 空指针,就告诉你说是空指针。 printStackTrace():提供对打印的堆栈跟踪信息的编程访问,会打出详细异常,异常名称,出错位置,便于调试用。 toString():返回此throwable的简短描述。 注意要点： 多个catch模块，子类在先，为了保证所有的catch都有存在的意义 finally模块在try-catch的return或者异常处理之前执行 在以下4种特殊情况下，finally块不会被执行：1）在finally语句块中抛出了异常且未处理。2）在前面的代码中用了System.exit()退出程序。3）程序所在的线程死亡。4）CPU出现异常被关闭。","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"java数据类型","slug":"java/javase/dataType","date":"2018-05-17T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/05/17/java/javase/dataType/","link":"","permalink":"https://marchnineteen.github.io/2018/05/17/java/javase/dataType/","excerpt":"","text":"1.Java 八大基本数据类型及其封装器类（位数为二进制位）字符类型char：默认值：\\u0000，16位，数据范围：\\u0000 - u\\ffff，存储Unicode码，用单引号赋值。封装类：Character 布尔类型boolean：默认值：false，1位，只有true和false两个取值。封装类：Boolean 数值类型整数类型：(最大存储容量为2的n次方减一，范围为负数2的n减一次方至2的n减一次方减一，n为位数，原理见计算机组成原理无符号数与有符号数) byte：默认值：0，8位，字节，最大存储数据量是255，存放的数据范围是-128~127之间。封装类：Byte short：默认值：0，16位，最大数据存储量是65536，数据范围是-32768~32767之间。封装类：Short int：默认值：0，32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。封装类：Integer long：默认值：0，64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。封装类：Long 浮点数类型： float：默认值：0.0f，32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。封装类：Float double：默认值：0.0d，64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。封装类：Double 对于数值类型的基本类型的取值范围，我们无需强制去记忆，因为它们的值都已经以常量的形式定义在对应的包装类中了。如： 基本类型byte 二进制位数：Byte.SIZE最小值：Byte.MIN_VALUE最大值：Byte.MAX_VALUE 基本类型short二进制位数：Short.SIZE最小值：Short.MIN_VALUE最大值：Short.MAX_VALUE 基本类型char二进制位数：Character.SIZE最小值：Character.MIN_VALUE最大值：Character.MAX_VALUE 基本类型double 二进制位数：Double.SIZE最小值：Double.MIN_VALUE最大值：Double.MAX_VALUE 注意：float、double两种类型的最小值与Float.MIN_VALUE、 Double.MIN_VALUE的值并不相同，实际上Float.MIN_VALUE和Double.MIN_VALUE分别指的是 float和double类型所能表示的最小正数。也就是说存在这样一种情况，0到±Float.MIN_VALUE之间的值float类型无法表示，0 到±Double.MIN_VALUE之间的值double类型无法表示。这并没有什么好奇怪的，因为这些范围内的数值超出了它们的精度范围。 2.数据类型之间的转换：简单类型数据间的转换自动转换：运算或者方法调用时，低精度自动转化为高精度，从低到高顺序：(byte，short，char)–int–long–float—double； 特例：int到float，long到float，long到double 是不会自动转换的，不然将会丢失精度。 强制转换：高精度转为低精度，可以使用强制转换；即你必须采用下面这种语句格式： int n=(int)3.14159/2;可以想象，这种转换肯定可能会导致溢出或精度的下降。 表达式的数据类型自动提升注意一下规则： ①所有的byte,short,char型的值将被提升为int型； ②如果有一个操作数是long型，计算结果是long型； ③如果有一个操作数是float型，计算结果是float型； ④如果有一个操作数是double型，计算结果是double型； 例， byte b; b=3; b=(byte)(b*3);//必须声明byte。 包装类过渡类型转换 简单类型的变量转换为相应的包装类，可以利用包装类的构造函数。即：Boolean(boolean value)、Character(char value)、Integer(int value)、Long(long value)、Float(float value)、Double(double value) 在各个包装类中，总有形为××Value()的方法，来得到其对应的简单类型数据。利用这种方法，也可以实现不同数值型变量间的转换，例如，对于一个双精度实型类，intValue()可以得到其对应的整型变量，而doubleValue()可以得到其对应的双精度实型变量 字符串与其它类型间的转换其它类型向字符串的转换： ①调用类的串转换方法:X.toString(); ②自动转换:X+&quot;&quot;; ③使用String的方法:String.valueOf(X);字符串作为值,向其它类型的转换： ①先转换成相应的封装器实例,再调用对应的方法转换成其它类型。例：new Float(&quot;11&quot;).doubleValue() ②静态parseXXX方法。 String s = &quot;1&quot;; byte b = Byte.parseByte( s ); short t = Short.parseShort( s ); int i = Integer.parseInt( s ); long l = Long.parseLong( s ); Float f = Float.parseFloat( s ); Double d = Double.parseDouble( s ); ③Character的getNumericValue(char ch)方法自动拆箱与自动装箱自动装箱：把基本类型用它们对应的包装类包装起来，使它们具有对象的特质，可以调用所对应的包装类所定义的方法，比如toString()等。 123456Integer i0 &#x3D; new Integer(0);&#x2F;&#x2F;基本的创建封装类对象Integer i1 &#x3D; 2;&#x2F;&#x2F;自动装箱Integer i1_ &#x3D; Integer.valueOf(2);&#x2F;&#x2F;自动装箱的本质，调用XX.valueof()方法&#96;&#96;&#96; 自动拆箱：跟自动装箱的方向相反，将Integer及Double这样的包装类的对象重新简化为基本类型的数据(自动拆箱时，一定要确保包装类的引用不为空) System.out.println(i1+2);//i1是我们上面通过自动装箱得到的一个integer对象，而这个对象是不能直接进行四则运算的，但是我们却给它+2，这样就必须将integer对象转变为基本数据类型（int），这个过程就是自动拆箱的过程 1234jdk装箱池（方法区中的常量池）：java的八种基本类型（Byte Short、Integer、Long、Character、Boolean、Float、Double），除Float及Double意外，其它六种都实现了常量池，但是他们只在大于等于-128且小于等于127时才能使用常量池，如果不在此范围内，则会new一个出来，保存在堆内存中。例子： Integer a = 1; Integer b = 1; Integer c = 144; Integer d = 144; Integer a1 = new Integer(1); Integer b1 = new Integer(1); System.out.println(a == b); //true System.out.println(a.equals(b)); //true System.out.println(a1 == b1); //false System.out.println(a1.equals(b1)); //true System.out.println(c == d); //false System.out.println(c.equals(d)); //true 在进行==比较的时候，在自动装箱池范围内的数据的引用是相同的，范围外的是不同的。 # 3.Java引用类型 Java有 5种引用类型（对象类型）：类 接口 数组 枚举 标注 引申：Java中的堆内存、栈内存、静态存储区 &gt; http://www.cnblogs.com/mingziday/p/4899212.html 栈（stack）存放基础数据类型以及对象的对象的引用 堆（heap）存放由new创建的对象和数组，即堆主要是用来存储对象的 方法区中的静态存储区存储static声明的静态变量 # 4.java字符编码 &gt; http://kxjhlele.iteye.com/blog/333211","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"java标识符与关键字","slug":"java/javase/javaKeyWord","date":"2018-05-16T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2018/05/16/java/javase/javaKeyWord/","link":"","permalink":"https://marchnineteen.github.io/2018/05/16/java/javase/javaKeyWord/","excerpt":"","text":"标识符 概念：就是用于给程序中的变量、类、方法命名的符号; 标识符规则：标识符可以有字母、数字、下划线_、和美元符号$组成，并且数字不能打头 标识符不能使java关键字和保留字，但可以包含关键字和保留字 标识符不能包含空格 标识符只能包含美元符号$，不能包含@、#等其他特殊字符 分隔符：分号; 花括号{} 方括号[] 括号() 空格 圆点.; Java关键字java中包含50个关键，所有关键字都是小写的 关键字列表： abstract抽象的 assert boolean break byte case catch char const(保留字) continue default do double else enum extends final finally float for if goto(保留字) implements import int interface long native new package private protected public return short static strictfp super switch synchronized this throw throws transient try void volatile while 三个特殊的直接量（iteral）;true false null 都不是关键字 final、finally、finalize的区别: final: final修饰变量，则等同于常量,变量不能修改 final修饰方法中的参数，称为最终参数，参数不能修改。 final修饰类，则类不能被继承 final修饰方法，则方法不能被重写。 finally: try-catch模块中使用finally，表示finally块则是无论异常是否发生，都会执行finally块的内容 finalize: 使用finalize在垃圾收集器确定这个对象未被引用时调用，表示在垃圾收集器将对象从内存中清除出去之前做一些清理工作。 子类可以覆盖该方法以实现资源清理工作，GC在回收对象之前调用该方法","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"springXMLSchema","slug":"spring/springXMLSchema","date":"2017-07-05T00:00:00.000Z","updated":"2021-07-01T08:01:52.085Z","comments":true,"path":"2017/07/05/spring/springXMLSchema/","link":"","permalink":"https://marchnineteen.github.io/2017/07/05/spring/springXMLSchema/","excerpt":"","text":"出处 http://www.jianshu.com/p/1e35c15d0cb8 参考资料 http://www.w3school.com.cn/schema/index.asp 自己理解整理： 基本概念： XML Schema也被称为XML Schema定义（XML Schema Definition，XSD）。和DTD一样，Schema也是XML的约束，同样用于定义合法的XML文档构建模块。与DTD不同的是，XML Schema是用一套预先定义好的XML元素和属性创建的，这些元素和属性规定了XML文档的结构和内容模式，且XML Schema规定XML文档实例的结构和每一个元素或属性的数据类型。另外，Schema相对于DTD有一个明显的好处就是，Schema是基于XML编写的，自己本身也是一个XML文档（文件后缀名为.xsd），而不是像DTD有自成一套的语法，这也是Schema能比DTD更被广泛应用的原因。 名称空间： 在编写了一个XML Schema约束文档后，通常需要把这个文档定义的元素和属性绑定到一个URI地址上，这个地址就叫做名称空间。接着XML文档通过这个名称空间告诉解析引擎，文档中的元素和属性来自哪里。名称空间有什么用呢？就是用来唯一标识元素和属性来自哪个Schema。简单来说，当一个XML实例文档引用了多个Schema的时候，倘若这些Schema定义了同名的元素或属性，名称空间就可以将它们区分开来。 引用其他Schema 自定义schema 给自己的文件命名方便其他文件调用 xmlns后的属性即表示该文件中的context属性来源于这个ns 修改XML实例文档:","categories":[{"name":"spring","slug":"spring","permalink":"https://marchnineteen.github.io/categories/spring/"}],"tags":[]},{"title":"ls指令学习","slug":"linux-command/ls","date":"2017-07-05T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2017/07/05/linux-command/ls/","link":"","permalink":"https://marchnineteen.github.io/2017/07/05/linux-command/ls/","excerpt":"","text":"命令格式：ls [选项] [目录名] 命令功能：列出目标目录中所有的子目录和文件。 常用参数： -a, –all 列出目录下的所有文件，包括以 . 开头的隐含文件 -A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。 -c 配合 -lt：根据 ctime 排序及显示 ctime (文件状态最后更改的时间)配合 -l：显示 ctime 但根据名称排序否则：根据 ctime 排序 -C 每栏由上至下列出项目 –color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是’never’、’always’或’auto’其中之一 -d, –directory 将目录象文件一样显示，而不是显示其下的文件。 -D, –dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G, –no-group 不列出任何有关组的信息 -h, –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H, –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=方式 指定在每个项目名称后加上指示符号&lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i, –inode 印出每个文件的 inode 号 -I, –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小。 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L, –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号链接本身的信息 -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r, –reverse 依相反次序排列 -R, –recursive 同时列出所有子目录层 -s, –size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 以下是可选用的 WORD 和它们代表的相应选项： extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t 以文件修改时间排序 -u 配合 -lt:显示访问时间而且依访问时间排序 配合 -l:显示访问时间但根据名称排序否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w, –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开","categories":[{"name":"linux-command","slug":"linux-command","permalink":"https://marchnineteen.github.io/categories/linux-command/"}],"tags":[]},{"title":"Spring MVC入门","slug":"spring/springMVC","date":"2017-07-05T00:00:00.000Z","updated":"2021-07-01T08:01:52.085Z","comments":true,"path":"2017/07/05/spring/springMVC/","link":"","permalink":"https://marchnineteen.github.io/2017/07/05/spring/springMVC/","excerpt":"","text":"1.架构 1.1架构图 1.2架构流程 1.用户发送请求至前端控制器DispatcherServlet 2.DispatcherServlet收到请求调用HandlerMapping处理器映射器。 3.处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。 4.DispatcherServlet通过HandlerAdapter处理器适配器调用处理器 5.执行处理器(Controller，也叫后端控制器)。 6.Controller执行完成返回ModelAndView 7.HandlerAdapter将controller执行结果ModelAndView返回 8.DispatcherServlet DispatcherServlet将ModelAndView传给ViewReslover视图解析器 9.ViewReslover解析后返回具体View 10.DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）。 11.DispatcherServlet响应用户","categories":[{"name":"spring","slug":"spring","permalink":"https://marchnineteen.github.io/categories/spring/"}],"tags":[]},{"title":"java集合框架","slug":"java/javase/collection","date":"2017-03-16T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2017/03/16/java/javase/collection/","link":"","permalink":"https://marchnineteen.github.io/2017/03/16/java/javase/collection/","excerpt":"","text":"Collection Set (extends Collection)Set是最简单的一种集合。集合中的对象不按特定的方式排序，并且没有重复对象。 Set接口主要实现了两个实现类： HashSet： HashSet类按照哈希算法来存取集合中的对象，存取速度比较快 TreeSet ：TreeSet类实现了SortedSet接口，能够对集合中的对象进行排序。 LinkedHashSet：具有HashSet的查询速度，且内部使用链表维护元素的顺序(插入的次序)。于是在使用迭代器遍历Set时，结果会按元素插入的次序显示。 List (extends Collection)实际上有两种List: 一种是基本的ArrayList,其优点在于随机访问元素，另一种是更强大的LinkedList,它并不是为快速随机访问设计的，而是具有一套更通用的方法。 List : 次序是List最重要的特点：它保证维护元素特定的顺序。List为Collection添加了许多方法，使得能够向List中间插入与移除元素(这只推荐LinkedList使用。)一个List可以生成ListIterator,使用它可以从两个方向遍历List,也可以从List中间插入和移除元素。 ArrayList : 由数组实现的List。允许对元素进行快速随机访问，但是向List中间插入与移除元素的速度很慢。ListIterator只应该用来由后向前遍历ArrayList,而不是用来插入和移除元素。因为那比LinkedList开销要大很多。 LinkedList : 对顺序访问进行了优化，向List中间插入与删除的开销并不大。随机访问则相对较慢。(使用ArrayList代替。)还具有下列方法：addFirst(), addLast(), getFirst(), getLast(), removeFirst() 和 removeLast(), 这些方法 (没有在任何接口或基类中定义过)使得LinkedList可以当作堆栈、队列和双向队列使用。 Queen (extends Collection)Map方法put(Object key, Object value)添加一个“值”(想要得东西)和与“值”相关联的“键”(key)(使用它来查找)。方法get(Object key)返回与给定“键”相关联的“值”。可以用containsKey()和containsValue()测试Map中是否包含某个“键”或“值”。标准的Java类库中包含了几种不同的Map：HashMap, TreeMap, LinkedHashMap, WeakHashMap, IdentityHashMap。它们都有同样的基本接口Map，但是行为、效率、排序策略、保存对象的生命周期和判定“键”等价的策略等各不相同。 执行效率是Map的一个大问题。看看get()要做哪些事，就会明白为什么在ArrayList中搜索“键”是相当慢的。而这正是HashMap提高速度的地方。HashMap使用了特殊的值，称为“散列码”(hash code)，来取代对键的缓慢搜索。“散列码”是“相对唯一”用以代表对象的int值，它是通过将该对象的某些信息进行转换而生成的。所有Java对象都能产生散列码，因为hashCode()是定义在基类Object中的方法。 HashMap就是使用对象的hashCode()进行快速查询的。此方法能够显着提高性能 Map : 维护“键值对”的关联性，使你可以通过“键”查找“值” HashMap : Map基于散列表的实现。插入和查询“键值对”的开销是固定的。可以通过构造器设置容量capacity和负载因子load factor，以调整容器的性能。 LinkedHashMap : 类似于HashMap，但是迭代遍历它时，取得“键值对”的顺序是其插入次序，或者是最近最少使用(LRU)的次序。只比HashMap慢一点。而在迭代访问时发而更快，因为它使用链表维护内部次序。 TreeMap : 基于红黑树数据结构的实现。查看“键”或“键值对”时，它们会被排序(次序由Comparabel或Comparator决定)。TreeMap的特点在于，你得到的结果是经过排序的。TreeMap是唯一的带有subMap()方法的Map，它可以返回一个子树。 WeakHashMao : 弱键(weak key)Map，Map中使用的对象也被允许释放: 这是为解决特殊问题设计的。如果没有map之外的引用指向某个“键”，则此“键”可以被垃圾收集器回收。 IdentifyHashMap : 使用==代替equals()对“键”作比较的hash map。专为解决特殊问题而设计 总结如下： 他们之间的区别： 集合框架初始化容量和扩容比较： ArrayList LinkList HashMap HashTable jdk1.7 初始容量 扩容条件 扩容大小 最大容量 jdk1.8 初始容量 10 1 &lt;&lt; 4(16) 11 扩容条件 在第一次add时扩容检测 扩容加载因子为(0.75)，第一个临界点在当HashMap中元素的数量大于table数组长度加载因子（160.75=12） 扩容加载因子(0.75)，当超出默认长度（int）（11*0.75）=8时 扩容大小 oldCapacity + (oldCapacity &gt;&gt; 1)，即大约原集合长度的1.5倍 oldThr &lt;&lt; 1(原长度*2) old*2+1(代码int newCapacity = (oldCapacity &lt;&lt; 1) + 1) 最大容量 Integer.MAX_VALUE - 8 1 &lt;&lt; 30 Integer.MAX_VALUE - 8 对于java中的各种集合类，根据底层的具体实现，小结了一下大致有3种扩容的方式： 1、对于以散列表为底层数据结构实现的，（譬如hashset，hashmap，hashtable等），扩容方式为当链表数组的非空元素除以数组大小超过加载因子时，链表数组长度变大（乘以2+1），然后进行重新散列。 2、对于以数组为底层数据结构实现的，譬如ArrayList，当数组满了之后，数组长度变大 oldCapacity + (oldCapacity &gt;&gt; 1)，然后将原数组中的数据复制到新数组中。 3、对于以链表结构实现的，譬如TreeSet，TreeMap，则是动态增加元素~~即每次加１即可。 注意点：为啥arrayList最大值是Integer.MAX_VALUE - 8：数组作为一个对象，需要一定的内存存储对象头信息，对象头信息最大占用内存不可超过8字节。 部分源码实现过程：hashMap put过程1.判断hash表是否为空，为空resize()方法创建表2.根据hash值获得hash表中桶的头结点，若头结点为空直接调用newNode()添加结点3.如果发生了hash冲突，先得到头结点进行比较，如果相同，替换节点值4.如果头结点头结点不相同，且此时已处于红黑树状态，调用putTreeVal()添加入树中5.如果还是处于链表状态，从头开始遍历链表，一旦找到相同的结点，就跳出循环，若到链表末尾，则添加一个结点6.若添加后达到红黑树的阈值，则转换为红黑树(从treeifyBin方法可以看到，当容量小于64时，不会进行红黑树转换，只会扩容)7.如果是添加一个数据，size将加一，如果达到阈值，则resize()扩容 hashMap resize首先获取新容量以及新阈值，然后根据新容量创建新表。如果是扩容操作，则需要进行rehash操作，通过e.hash&amp;oldCap将链表分为两列，更好地均匀分布在新表中。 linkList 中间插入过程例：在A，B两个连续结点中插入C结点,形成ACB 1.创建一个新结点，将新节点的后继指针指向B，前继指针指向A2.将B的前指针指向C3.根据A是否为空判断，A为空该节点为头结点，重置first结点；不为空A的后指针指向C","categories":[{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"}],"tags":[]},{"title":"Filter详解","slug":"servlet/filter","date":"2017-02-28T00:00:00.000Z","updated":"2021-07-01T08:01:52.081Z","comments":true,"path":"2017/02/28/servlet/filter/","link":"","permalink":"https://marchnineteen.github.io/2017/02/28/servlet/filter/","excerpt":"","text":"web.xml中元素执行的顺序listener-&gt;filter-&gt;struts拦截器-&gt;servlet。 1.过滤器的概念 Java中的Filter 并不是一个标准的Servlet ，它不能处理用户请求，也不能对客户端生成响应。 主要用于对HttpServletRequest 进行预处理，也可以对HttpServletResponse 进行后处理，是个典型的处理链。 优点：过滤链的好处是，执行过程中任何时候都可以打断，只要不执行chain.doFilter()就不会再执行后面的过滤器和请求的内容。而在实际使用时，就要特别注意过滤链的执行顺序问题 2.过滤器的作用描述 在HttpServletRequest 到达Servlet 之前，拦截客户的HttpServletRequest 。根据需要检查HttpServletRequest ，也可以修改HttpServletRequest 头和数据。在HttpServletResponse 到达客户端之前，拦截HttpServletResponse 。根据需要检查HttpServletResponse ，可以修改HttpServletResponse 头和数据。 3.过滤器的执行流程 4.Filter接口 4.1 如何驱动 在 web 应用程序启动时，web 服务器将根据 web.xml 文件中的配置信息来创建每个注册的 Filter 实例对象，并将其保存在服务器的内存中 4.2 方法介绍 init() Init 方法在 Filter 生命周期中仅执行一次，web 容器在调用 init 方法时 tomcat启动时出调用 doFilter() Filter 链的执行 过滤方法在请求发出后立即调用，过滤特定的URL destory() 在Web容器卸载 Filter 对象之前被调用。该方法在Filter的生命周期中仅执行一次。在这个方法中，可以释放过滤器使用的资源。 5.FilterChain接口 5.1 如何实例化 代表当前 Filter 链的对象。由容器实现，容器将其实例作为参数传入过滤器对象的doFilter()方法中 5.2 作用 调用过滤器链中的下一个过滤器 filter实例： web.xml配置: 编码拦截器： 日志拦截器： HelloServlet类： 结果： 总结： 1.过滤器执行流程 2.常用过滤器 FilterConfig接口1、与普通的Servlet程序一样，Filter程序也很可能需要访问Servlet容器。Servlet规范将代表ServletContext对象和Filter的配置参数信息都封装到一个称为FilterConfig的对象中。 2、FilterConfig接口则用于定义FilterConfig对象应该对外提供的方法，以便在Filter程序中可以调用这些方法来获取ServletContext对象，以及获取在web.xml文件中为Filter设置的友好名称和初始化参数。 3、FilterConfig接口定义的各个方法： 1234567891011public interfaceFilterConfig &#123; String getFilterName(); ServletContext getServletContext(); String getInitParameter(String var1); Enumeration getInitParameterNames();&#125; getFilterName方法，返回元素的设置值。 getServletContext方法，返回FilterConfig对象中所包装的ServletContext对象的引用。 getInitParameter方法，用于返回在web.xml文件中为Filter所设置的某个名称的初始化的参数值。 getInitParameterNames方法，返回一个Enumeration集合对象。","categories":[{"name":"servlet","slug":"servlet","permalink":"https://marchnineteen.github.io/categories/servlet/"}],"tags":[]}],"categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://marchnineteen.github.io/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"other","slug":"other","permalink":"https://marchnineteen.github.io/categories/other/"},{"name":"JavaSE","slug":"JavaSE","permalink":"https://marchnineteen.github.io/categories/JavaSE/"},{"name":"active","slug":"active","permalink":"https://marchnineteen.github.io/categories/active/"},{"name":"spring","slug":"spring","permalink":"https://marchnineteen.github.io/categories/spring/"},{"name":"日常问题记录","slug":"日常问题记录","permalink":"https://marchnineteen.github.io/categories/%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"name":"cache","slug":"cache","permalink":"https://marchnineteen.github.io/categories/cache/"},{"name":"tool","slug":"tool","permalink":"https://marchnineteen.github.io/categories/tool/"},{"name":"database","slug":"database","permalink":"https://marchnineteen.github.io/categories/database/"},{"name":"java-design-patterns","slug":"java-design-patterns","permalink":"https://marchnineteen.github.io/categories/java-design-patterns/"},{"name":"datastructure","slug":"datastructure","permalink":"https://marchnineteen.github.io/categories/datastructure/"},{"name":"linux-command","slug":"linux-command","permalink":"https://marchnineteen.github.io/categories/linux-command/"},{"name":"nginx","slug":"nginx","permalink":"https://marchnineteen.github.io/categories/nginx/"},{"name":"JVM","slug":"JVM","permalink":"https://marchnineteen.github.io/categories/JVM/"},{"name":"servlet","slug":"servlet","permalink":"https://marchnineteen.github.io/categories/servlet/"}],"tags":[]}